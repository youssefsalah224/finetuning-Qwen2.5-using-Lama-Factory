{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "R4gFkGQA4_BW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2be235a7ea4b4719b127176d86721cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_780acf6c26da4ff2aba3c7362fb4a6ad",
              "IPY_MODEL_18bb84a13a9046d2ac3b74a3c571f426",
              "IPY_MODEL_a91bbaecef04424cb3fc3a22517a2c0e"
            ],
            "layout": "IPY_MODEL_f0beb83ab23f4dfb9376327ec0b36f03"
          }
        },
        "780acf6c26da4ff2aba3c7362fb4a6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_527b0d35076748cdb9e97be82cd2067a",
            "placeholder": "​",
            "style": "IPY_MODEL_84d45a0aded24c6b966ce6b6c488b5a8",
            "value": "config.json: 100%"
          }
        },
        "18bb84a13a9046d2ac3b74a3c571f426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed4f4a8e657499680e254ad2e533392",
            "max": 660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88e6446c5de840a88fee3b84cc4bd731",
            "value": 660
          }
        },
        "a91bbaecef04424cb3fc3a22517a2c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfe7fef761864e38b615bdb8d79ccd8f",
            "placeholder": "​",
            "style": "IPY_MODEL_799450914150444d830227f691f151bd",
            "value": " 660/660 [00:00&lt;00:00, 72.3kB/s]"
          }
        },
        "f0beb83ab23f4dfb9376327ec0b36f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527b0d35076748cdb9e97be82cd2067a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84d45a0aded24c6b966ce6b6c488b5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ed4f4a8e657499680e254ad2e533392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e6446c5de840a88fee3b84cc4bd731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfe7fef761864e38b615bdb8d79ccd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799450914150444d830227f691f151bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26de4e184bfe4bc1a02ae596f5d2925e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8784a3305d90425b8d5c0540b92bec2a",
              "IPY_MODEL_0bb1ea4968414974bfb75126beb02417",
              "IPY_MODEL_65e836f497fe48948d0d3756c91318ba"
            ],
            "layout": "IPY_MODEL_85c78baef07e45e6bd578549eba2e72d"
          }
        },
        "8784a3305d90425b8d5c0540b92bec2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_670de8e33e3c43daa9c3b5b4e56d2f7a",
            "placeholder": "​",
            "style": "IPY_MODEL_b695399ff55b4529998ba0b8902a5dfd",
            "value": "model.safetensors: 100%"
          }
        },
        "0bb1ea4968414974bfb75126beb02417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b84eb7a1c0db4dbcb19e5ab561f72b7c",
            "max": 3087467144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffcbf7b557174061b13265d349630dfe",
            "value": 3087467144
          }
        },
        "65e836f497fe48948d0d3756c91318ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d627a7dbf6e644e38d1de394406fd4e0",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc6b6efa2ef4e23b9f8d7a3e14fb3c0",
            "value": " 3.09G/3.09G [01:26&lt;00:00, 29.0MB/s]"
          }
        },
        "85c78baef07e45e6bd578549eba2e72d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670de8e33e3c43daa9c3b5b4e56d2f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b695399ff55b4529998ba0b8902a5dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b84eb7a1c0db4dbcb19e5ab561f72b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffcbf7b557174061b13265d349630dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d627a7dbf6e644e38d1de394406fd4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc6b6efa2ef4e23b9f8d7a3e14fb3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfb5fadbbf6348b4871173ffbc221e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4728234fd5b41f4abfd67c4b557ddb2",
              "IPY_MODEL_58a99777827b4027a3af7c6d368c4a83",
              "IPY_MODEL_a5ff943d1c494164bdf7ded07436983f"
            ],
            "layout": "IPY_MODEL_dbe4f8a6b3f7401888beaeafc1ca1efb"
          }
        },
        "a4728234fd5b41f4abfd67c4b557ddb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fffefe378864922b1257c509ebe9267",
            "placeholder": "​",
            "style": "IPY_MODEL_72a0391eb33343bb9053dcc3f913d361",
            "value": "generation_config.json: 100%"
          }
        },
        "58a99777827b4027a3af7c6d368c4a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8f27708d604029a8b7e0ba7c98fe46",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f7a170752054d8b9b6b06b55ca8d4af",
            "value": 242
          }
        },
        "a5ff943d1c494164bdf7ded07436983f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d46b4c66a645aeb425fa585aebebf9",
            "placeholder": "​",
            "style": "IPY_MODEL_660c3d30238042a7b047a38f792a1666",
            "value": " 242/242 [00:00&lt;00:00, 21.8kB/s]"
          }
        },
        "dbe4f8a6b3f7401888beaeafc1ca1efb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fffefe378864922b1257c509ebe9267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a0391eb33343bb9053dcc3f913d361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d8f27708d604029a8b7e0ba7c98fe46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f7a170752054d8b9b6b06b55ca8d4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5d46b4c66a645aeb425fa585aebebf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660c3d30238042a7b047a38f792a1666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9444dd080a94d83aaa7fbdcd58f2339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fcefb0f5c98490fac80a4d43142a677",
              "IPY_MODEL_8815e2b045d54199b71a0c537e6d28ae",
              "IPY_MODEL_05108d5d07414f459305c458b5d3156b"
            ],
            "layout": "IPY_MODEL_1a40e3e907e64ca5a204b406faeab4da"
          }
        },
        "8fcefb0f5c98490fac80a4d43142a677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2707fe77cee64cfe9526467151d98374",
            "placeholder": "​",
            "style": "IPY_MODEL_e546b9ae9d9640b587001f820fe23d1d",
            "value": "tokenizer_config.json: "
          }
        },
        "8815e2b045d54199b71a0c537e6d28ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cf0c35bc3444def84b00f5375d67c47",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0115c416aa8f4b89bb01591ee8f03eb8",
            "value": 1
          }
        },
        "05108d5d07414f459305c458b5d3156b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f441c6462c8d4b86b14b19d10fdef38f",
            "placeholder": "​",
            "style": "IPY_MODEL_a9004f0603d841b9a5a22485afe63251",
            "value": " 7.30k/? [00:00&lt;00:00, 748kB/s]"
          }
        },
        "1a40e3e907e64ca5a204b406faeab4da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2707fe77cee64cfe9526467151d98374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e546b9ae9d9640b587001f820fe23d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cf0c35bc3444def84b00f5375d67c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0115c416aa8f4b89bb01591ee8f03eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f441c6462c8d4b86b14b19d10fdef38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9004f0603d841b9a5a22485afe63251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d70ac56db94265a8229501166326e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfcadffa355b4ae2aadc76e4ecf448e4",
              "IPY_MODEL_5ce9e0a7e5474001b8c9f7cb4aa618e6",
              "IPY_MODEL_82107fc8ba054a6a8f7eb7976b44e89c"
            ],
            "layout": "IPY_MODEL_71f2de99cb8344ebb7e684d200336c72"
          }
        },
        "dfcadffa355b4ae2aadc76e4ecf448e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4392585a8c0140998774376251ef3311",
            "placeholder": "​",
            "style": "IPY_MODEL_b2aad076cad5416a8060c89eb221227e",
            "value": "vocab.json: "
          }
        },
        "5ce9e0a7e5474001b8c9f7cb4aa618e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee2b5536f7a4c1ba09c2b1e3552dc31",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f80d68b5a0e9468d9d1d1a976fb57673",
            "value": 1
          }
        },
        "82107fc8ba054a6a8f7eb7976b44e89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696d0c5f1374490bad0d0843de314ff0",
            "placeholder": "​",
            "style": "IPY_MODEL_52a7d62477c643aaa467e9170f4ec40e",
            "value": " 2.78M/? [00:00&lt;00:00, 8.48MB/s]"
          }
        },
        "71f2de99cb8344ebb7e684d200336c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4392585a8c0140998774376251ef3311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2aad076cad5416a8060c89eb221227e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dee2b5536f7a4c1ba09c2b1e3552dc31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f80d68b5a0e9468d9d1d1a976fb57673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "696d0c5f1374490bad0d0843de314ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a7d62477c643aaa467e9170f4ec40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdfa1886cd1b4571aee280a96c5d22cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b090ffb0c444bf9871eb1dbc672fe0e",
              "IPY_MODEL_4bcf9085d67a4bbabe37bd1181490b71",
              "IPY_MODEL_4efe2123afcb4136a0703b3724156171"
            ],
            "layout": "IPY_MODEL_486575185dc74a328f75e753cc4cf8d3"
          }
        },
        "5b090ffb0c444bf9871eb1dbc672fe0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb6662a703d044a1802170e6c9c827d7",
            "placeholder": "​",
            "style": "IPY_MODEL_2b689308e9b046d3b06098fb373d8235",
            "value": "merges.txt: "
          }
        },
        "4bcf9085d67a4bbabe37bd1181490b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3c99fb6530c43abb9e0d414a0c25322",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9838d20bdd0d44c89645dc35d76835b3",
            "value": 1
          }
        },
        "4efe2123afcb4136a0703b3724156171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6668bed6aaa4152a452ed53f6942041",
            "placeholder": "​",
            "style": "IPY_MODEL_bdf15bddbe9f4eb49c223effe624c6c9",
            "value": " 1.67M/? [00:00&lt;00:00, 5.17MB/s]"
          }
        },
        "486575185dc74a328f75e753cc4cf8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb6662a703d044a1802170e6c9c827d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b689308e9b046d3b06098fb373d8235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3c99fb6530c43abb9e0d414a0c25322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9838d20bdd0d44c89645dc35d76835b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6668bed6aaa4152a452ed53f6942041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf15bddbe9f4eb49c223effe624c6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69a3c36c011a4cd08b1de180ee9675e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47b8305027ce48c8a1daf4fc721bb9ba",
              "IPY_MODEL_0503fa503bee41f788b5fc26c6cbf86e",
              "IPY_MODEL_76bccfc6af884ce6b6db0c6dfc8b27f2"
            ],
            "layout": "IPY_MODEL_bdace639fdd845bca57c745ce5758a95"
          }
        },
        "47b8305027ce48c8a1daf4fc721bb9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb4df3556e34428adbf847823d08800",
            "placeholder": "​",
            "style": "IPY_MODEL_06e51cf22a6543588c966a4c9eb2aaf7",
            "value": "tokenizer.json: "
          }
        },
        "0503fa503bee41f788b5fc26c6cbf86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63b8943bf6ec4962b55fb78295110a01",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a27dca14af2441938892894d836b565a",
            "value": 1
          }
        },
        "76bccfc6af884ce6b6db0c6dfc8b27f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e04449c19b99420490af918b01665e0f",
            "placeholder": "​",
            "style": "IPY_MODEL_b9985b7a76cc41549bf9781ca7e1d1f5",
            "value": " 7.03M/? [00:00&lt;00:00, 16.5MB/s]"
          }
        },
        "bdace639fdd845bca57c745ce5758a95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb4df3556e34428adbf847823d08800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e51cf22a6543588c966a4c9eb2aaf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63b8943bf6ec4962b55fb78295110a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a27dca14af2441938892894d836b565a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e04449c19b99420490af918b01665e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9985b7a76cc41549bf9781ca7e1d1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youssefsalah224/finetuning-Qwen2.5-using-Lama-Factory/blob/main/finetuning_Qwen2_5_using_Lama_Factory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzExaTCGnZRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a71f608-b819-4083-cf09-51b83683f26e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "zDV3lCZHxwOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "E3oSbcZBVlDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU transformers==4.48.3 datasets==3.2.0 optimum==1.24.0\n",
        "!pip install -qU openai==1.61.0 wandb\n",
        "!pip install -qU json-repair==0.29.1\n",
        "!pip install -qU faker==35.2.0\n",
        "!pip install -qU vllm==0.7.2"
      ],
      "metadata": {
        "id": "vhrM7Kgyxydu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2654281-8a47-4ab2-bace-1423648f6168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.6/460.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.3/264.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.2/343.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.4/914.4 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "!cd LLaMA-Factory && pip install -e ."
      ],
      "metadata": {
        "id": "8526F9lVKilu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdbda099-3175-474a-8f00-d51f71990a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 382, done.\u001b[K\n",
            "remote: Counting objects: 100% (382/382), done.\u001b[K\n",
            "remote: Compressing objects: 100% (293/293), done.\u001b[K\n",
            "remote: Total 382 (delta 80), reused 324 (delta 74), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (382/382), 10.04 MiB | 15.42 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers!=4.52.0,<=4.56.1,>=4.49.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets<=4.0.0,>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (3.2.0)\n",
            "Requirement already satisfied: accelerate<=1.10.1,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (1.10.1)\n",
            "Requirement already satisfied: peft<=0.17.1,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.17.1)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting gradio<=5.45.0,>=4.38.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading gradio-5.45.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (3.10.0)\n",
            "Collecting tyro<0.9.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (1.16.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.2.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
            "Collecting modelscope>=1.14.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading modelscope-1.30.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hf-transfer in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.1.9)\n",
            "Collecting safetensors<=0.5.3 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fire (from llamafactory==0.9.4.dev0)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (6.0.2)\n",
            "Collecting pydantic<=2.10.6 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.35.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.116.2)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (3.0.2)\n",
            "Collecting av (from llamafactory==0.9.4.dev0)\n",
            "  Downloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (2.5.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (0.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.12.15)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.1.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.13.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.13.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.11.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.13.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.17.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.15.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->llamafactory==0.9.4.dev0)\n",
            "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,<=4.56.1,>=4.49.0->llamafactory==0.9.4.dev0) (2024.11.6)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,<=4.56.1,>=4.49.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.12/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn->llamafactory==0.9.4.dev0) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn->llamafactory==0.9.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->llamafactory==0.9.4.dev0) (3.1.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.1.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->llamafactory==0.9.4.dev0) (4.9.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.20.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (1.1.10)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (4.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (2.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.10.1,>=1.3.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Downloading gradio-5.45.0-py3-none-any.whl (60.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.30.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=28435 sha256=fb0c9e5a54c6353d23d03463b4f80e7563fe820f91c840fb1fdaeab46b9f6077\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p0zfq57a/wheels/68/8b/5e/52f9888e6a91a2651260d603137c052b925af896da6e32a3f7\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: shtab, safetensors, pydantic-core, fire, av, pydantic, modelscope, tyro, tokenizers, transformers, gradio, trl, llamafactory\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.9\n",
            "    Uninstalling pydantic-2.11.9:\n",
            "      Successfully uninstalled pydantic-2.11.9\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.46.0\n",
            "    Uninstalling gradio-5.46.0:\n",
            "      Successfully uninstalled gradio-5.46.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mcp 1.14.1 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.10.6 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed av-15.1.0 fire-0.7.1 gradio-5.45.0 llamafactory-0.9.4.dev0 modelscope-1.30.0 pydantic-2.10.6 pydantic-core-2.27.2 safetensors-0.5.3 shtab-1.7.2 tokenizers-0.22.1 transformers-4.56.1 trl-0.9.6 tyro-0.8.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "\n",
        "# Login to Weights & Biases\n",
        "wandb.login(key=userdata.get('wandb'))\n",
        "\n",
        "# Login to Hugging Face\n",
        "hf_token = userdata.get('newhuggingface')\n",
        "!hf auth login --token {hf_token}"
      ],
      "metadata": {
        "id": "65ZhrnavyL0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de56c845-69a2-4b38-b70d-f625e51215a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoussefsalah1357\u001b[0m (\u001b[33myoussefsalah1357-new\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `newprojj` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `newprojj`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "uLdOa2oSyuBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from os.path import join\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Literal\n",
        "from datetime import datetime\n",
        "import json_repair\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "data_dir = \"/gdrive/MyDrive/llm-finetune\"\n",
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "device = \"cuda\"\n",
        "torch_dtype = None\n",
        "\n",
        "def parse_json(text):\n",
        "    try:\n",
        "        return json_repair.loads(text)\n",
        "    except:\n",
        "        return None"
      ],
      "metadata": {
        "id": "y8utsMq7y_TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "0v79ic58xboK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks"
      ],
      "metadata": {
        "id": "UDKfM9Ua00SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"\"\"\n",
        "ذكرت مجلة فوربس أن العائلة تلعب دورا محوريا في تشكيل علاقة الأفراد بالمال،\n",
        " حيث تتأثر هذه العلاقة بأنماط السلوك المالي المتوارثة عبر الأجيال.\n",
        "\n",
        "التقرير الذي يستند إلى أبحاث الأستاذ الجامعي شاين إنيت حول\n",
        "الرفاه المالي يوضح أن لكل شخص \"شخصية مالية\" تتحدد وفقا لطريقة\n",
        " تفاعله مع المال، والتي تتأثر بشكل مباشر بتربية الأسرة وتجارب الطفولة.\n",
        "\n",
        " الأبعاد الثلاثة للعلاقة بالمال\n",
        "بحسب الدراسة، هناك ثلاثة أبعاد رئيسية تشكّل علاقتنا بالمال:\n",
        "\n",
        "الاكتساب (A): يميل الأفراد الذين ينتمون لهذا\n",
        " البعد إلى اعتبار المال سلعة قابلة للجمع، حيث يرون\n",
        "في تحقيق الثروة هدفا بحد ذاته. والجانب السلبي لهذا\n",
        " النمط هو إمكانية التحول إلى هوس بالثروة أو العكس،\n",
        " أي رفض تام لاكتساب المال باعتباره مصدرا للفساد.\n",
        "\n",
        "الاستخدام (U): يرى هؤلاء الأشخاص المال أداة للتمتع بالحياة، حيث يربطون قيمته بقدرته على توفير\n",
        "المتعة والراحة. ومع ذلك، قد يصبح\n",
        "البعض مدمنا على الإنفاق، في حين يتجه آخرون إلى التقشف المفرط خوفا من المستقبل.\n",
        "\n",
        "الإدارة (M): أصحاب هذا النمط يعتبرون المال مسؤولية تتطلب التخطيط الدقيق. لكن في بعض الحالات،\n",
        " قد يتحول الأمر إلى هوس مفرط بإدارة الإنفاق، مما يؤثر سلبا على العلاقات الشخصية.\n",
        "\n",
        " كيف تؤثر العائلة على علاقتنا بالمال؟\n",
        "يشير التقرير إلى أن التجارب الأسرية تلعب دورا رئيسيا في تحديد\n",
        " \"الشخصية المالية\" لكل فرد، على سبيل المثال، إذا كان أحد الوالدين يعتمد على المال\n",
        "كمكافأة للسلوك الجيد، فقد يتبنى الطفل لاحقا النمط نفسه في حياته البالغة.\n",
        "\n",
        "لتحليل هذه التأثيرات بشكل دقيق، طورت رابطة العلاج المالي\n",
        "(Financial Therapy Association) أداة تسمى مخطط الجينوم المالي (Money Genogram)،\n",
        "وهو نموذج يُستخدم لتحديد الأنماط المالية داخل العائلة.\n",
        "\n",
        "تتضمن هذه الأداة:\n",
        "\n",
        "رسم شجرة عائلية.\n",
        "تصنيف أفراد العائلة وفقا للأبعاد الثلاثة للعلاقة بالمال (A ،U ،M).\n",
        "تحديد ما إذا كان السلوك المالي لكل فرد صحيا (+) أو غير صحي (-).\n",
        "على سبيل المثال، إذا نشأ شخص في عائلة\n",
        "اعتادت على الإنفاق المفرط، فقد يكون لديه ميل قوي إلى اتباع النمط نفسه،\n",
        " أو العكس تماما، حيث يصبح مقتصدا بشكل مبالغ فيه كرد فعل نفسي.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ShkKHFV-01gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "StoryCategory = Literal[\n",
        "    \"politics\", \"sports\", \"art\", \"technology\", \"economy\",\n",
        "    \"health\", \"entertainment\", \"science\",\n",
        "    \"not_specified\"\n",
        "]\n",
        "\n",
        "EntityType = Literal[\n",
        "    \"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"tie\",\n",
        "    \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"\n",
        "]\n",
        "\n",
        "class Entity(BaseModel):\n",
        "    entity_value: str = Field(..., description=\"The actual name or value of the entity.\")\n",
        "    entity_type: EntityType = Field(..., description=\"The type of recognized entity.\")\n",
        "\n",
        "class NewsDetails(BaseModel):\n",
        "    story_title: str = Field(..., min_length=5, max_length=300,\n",
        "                             description=\"A fully informative and SEO optimized title of the story.\")\n",
        "\n",
        "    story_keywords: List[str] = Field(..., min_items=1,\n",
        "                                      description=\"Relevant keywords associated with the story.\")\n",
        "\n",
        "    story_summary: List[str] = Field(\n",
        "                                    ..., min_items=1, max_items=5,\n",
        "                                    description=\"Summarized key points about the story (1-5 points).\"\n",
        "                                )\n",
        "\n",
        "    story_category: StoryCategory = Field(..., description=\"Category of the news story.\")\n",
        "\n",
        "    story_entities: List[Entity] = Field(..., min_items=1, max_items=10,\n",
        "                                        description=\"List of identified entities in the story.\")\n"
      ],
      "metadata": {
        "id": "5Uq6gtPO0-np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "details_extraction_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"You are an NLP data paraser.\",\n",
        "            \"You will be provided by an Arabic text associated with a Pydantic scheme.\",\n",
        "            \"Generate the ouptut in the same story language.\",\n",
        "            \"You have to extract JSON details from text according the Pydantic details.\",\n",
        "            \"Extract details as mentioned in text.\",\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"## Story:\",\n",
        "            story.strip(),\n",
        "            \"\",\n",
        "\n",
        "            \"## Pydantic Details:\",\n",
        "            json.dumps(\n",
        "                NewsDetails.model_json_schema(), ensure_ascii=False\n",
        "            ),\n",
        "            \"\",\n",
        "\n",
        "            \"## Story Details:\",\n",
        "            \"```json\"\n",
        "        ])\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "N6838nmZ5Nsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation"
      ],
      "metadata": {
        "id": "w1E3YIOW-f_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslatedStory(BaseModel):\n",
        "    translated_title: str = Field(..., min_length=5, max_length=300,\n",
        "                                  description=\"Suggested translated title of the news story.\")\n",
        "    translated_content: str = Field(..., min_length=5,\n",
        "                                    description=\"Translated content of the news story.\")\n",
        "\n",
        "targeted_lang = \"English\"\n",
        "\n",
        "translation_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"You are a professional translator.\",\n",
        "            \"You will be provided by an Arabic text.\",\n",
        "            \"You have to translate the text into the `Targeted Language`.\",\n",
        "            \"Follow the provided Scheme to generate a JSON\",\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":  \"\\n\".join([\n",
        "            \"## Story:\",\n",
        "            story.strip(),\n",
        "            \"\",\n",
        "\n",
        "            \"## Pydantic Details:\",\n",
        "            json.dumps( TranslatedStory.model_json_schema(), ensure_ascii=False ),\n",
        "            \"\",\n",
        "\n",
        "            \"## Targeted Language:\",\n",
        "            targeted_lang,\n",
        "            \"\",\n",
        "\n",
        "            \"## Translated Story:\",\n",
        "            \"```json\"\n",
        "\n",
        "        ])\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "y6J9rGpY-jmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "wkVOXy3y7YI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device_map=\"auto\"\n",
        "\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
      ],
      "metadata": {
        "id": "6Au-Yng57ZZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "2be235a7ea4b4719b127176d86721cf0",
            "780acf6c26da4ff2aba3c7362fb4a6ad",
            "18bb84a13a9046d2ac3b74a3c571f426",
            "a91bbaecef04424cb3fc3a22517a2c0e",
            "f0beb83ab23f4dfb9376327ec0b36f03",
            "527b0d35076748cdb9e97be82cd2067a",
            "84d45a0aded24c6b966ce6b6c488b5a8",
            "1ed4f4a8e657499680e254ad2e533392",
            "88e6446c5de840a88fee3b84cc4bd731",
            "dfe7fef761864e38b615bdb8d79ccd8f",
            "799450914150444d830227f691f151bd",
            "26de4e184bfe4bc1a02ae596f5d2925e",
            "8784a3305d90425b8d5c0540b92bec2a",
            "0bb1ea4968414974bfb75126beb02417",
            "65e836f497fe48948d0d3756c91318ba",
            "85c78baef07e45e6bd578549eba2e72d",
            "670de8e33e3c43daa9c3b5b4e56d2f7a",
            "b695399ff55b4529998ba0b8902a5dfd",
            "b84eb7a1c0db4dbcb19e5ab561f72b7c",
            "ffcbf7b557174061b13265d349630dfe",
            "d627a7dbf6e644e38d1de394406fd4e0",
            "2cc6b6efa2ef4e23b9f8d7a3e14fb3c0",
            "cfb5fadbbf6348b4871173ffbc221e69",
            "a4728234fd5b41f4abfd67c4b557ddb2",
            "58a99777827b4027a3af7c6d368c4a83",
            "a5ff943d1c494164bdf7ded07436983f",
            "dbe4f8a6b3f7401888beaeafc1ca1efb",
            "3fffefe378864922b1257c509ebe9267",
            "72a0391eb33343bb9053dcc3f913d361",
            "9d8f27708d604029a8b7e0ba7c98fe46",
            "3f7a170752054d8b9b6b06b55ca8d4af",
            "b5d46b4c66a645aeb425fa585aebebf9",
            "660c3d30238042a7b047a38f792a1666",
            "e9444dd080a94d83aaa7fbdcd58f2339",
            "8fcefb0f5c98490fac80a4d43142a677",
            "8815e2b045d54199b71a0c537e6d28ae",
            "05108d5d07414f459305c458b5d3156b",
            "1a40e3e907e64ca5a204b406faeab4da",
            "2707fe77cee64cfe9526467151d98374",
            "e546b9ae9d9640b587001f820fe23d1d",
            "7cf0c35bc3444def84b00f5375d67c47",
            "0115c416aa8f4b89bb01591ee8f03eb8",
            "f441c6462c8d4b86b14b19d10fdef38f",
            "a9004f0603d841b9a5a22485afe63251",
            "84d70ac56db94265a8229501166326e3",
            "dfcadffa355b4ae2aadc76e4ecf448e4",
            "5ce9e0a7e5474001b8c9f7cb4aa618e6",
            "82107fc8ba054a6a8f7eb7976b44e89c",
            "71f2de99cb8344ebb7e684d200336c72",
            "4392585a8c0140998774376251ef3311",
            "b2aad076cad5416a8060c89eb221227e",
            "dee2b5536f7a4c1ba09c2b1e3552dc31",
            "f80d68b5a0e9468d9d1d1a976fb57673",
            "696d0c5f1374490bad0d0843de314ff0",
            "52a7d62477c643aaa467e9170f4ec40e",
            "bdfa1886cd1b4571aee280a96c5d22cd",
            "5b090ffb0c444bf9871eb1dbc672fe0e",
            "4bcf9085d67a4bbabe37bd1181490b71",
            "4efe2123afcb4136a0703b3724156171",
            "486575185dc74a328f75e753cc4cf8d3",
            "eb6662a703d044a1802170e6c9c827d7",
            "2b689308e9b046d3b06098fb373d8235",
            "b3c99fb6530c43abb9e0d414a0c25322",
            "9838d20bdd0d44c89645dc35d76835b3",
            "a6668bed6aaa4152a452ed53f6942041",
            "bdf15bddbe9f4eb49c223effe624c6c9",
            "69a3c36c011a4cd08b1de180ee9675e1",
            "47b8305027ce48c8a1daf4fc721bb9ba",
            "0503fa503bee41f788b5fc26c6cbf86e",
            "76bccfc6af884ce6b6db0c6dfc8b27f2",
            "bdace639fdd845bca57c745ce5758a95",
            "cbb4df3556e34428adbf847823d08800",
            "06e51cf22a6543588c966a4c9eb2aaf7",
            "63b8943bf6ec4962b55fb78295110a01",
            "a27dca14af2441938892894d836b565a",
            "e04449c19b99420490af918b01665e0f",
            "b9985b7a76cc41549bf9781ca7e1d1f5"
          ]
        },
        "outputId": "110fdc8a-5d20-4bd8-cbf8-72557912dbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2be235a7ea4b4719b127176d86721cf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26de4e184bfe4bc1a02ae596f5d2925e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfb5fadbbf6348b4871173ffbc221e69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9444dd080a94d83aaa7fbdcd58f2339"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84d70ac56db94265a8229501166326e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdfa1886cd1b4571aee280a96c5d22cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69a3c36c011a4cd08b1de180ee9675e1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "9T3NyBjaRn1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13993054-13c7-40eb-fa81-7533b28d5052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 1536)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
              "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
              "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    details_extraction_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")\n",
        "\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "coJEFfI98amn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e4a931-e653-4aeb-a545-eb73cc750aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "vZfYD0K5-SLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436716d1-87f5-41f4-d106-aeee266b92d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"story_title\": \"How Family Influences Financial Behavior\",\n",
            "  \"story_keywords\": [\n",
            "    \"family influence\",\n",
            "    \"financial behavior\",\n",
            "    \"moneymaking\",\n",
            "    \"money management\",\n",
            "    \"personal finance\"\n",
            "  ],\n",
            "  \"story_summary\": [\n",
            "    \"Family plays a crucial role in shaping individuals' financial relationships.\",\n",
            "    \"Individuals inherit certain financial behaviors through their families.\"\n",
            "  ],\n",
            "  \"story_category\": \"economy\",\n",
            "  \"story_entities\": [\n",
            "    {\n",
            "      \"entity_value\": \"Families\",\n",
            "      \"entity_type\": \"location\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"Financial Therapists\",\n",
            "      \"entity_type\": \"organization\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    translation_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "UqSsu4dg_qYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Distillation"
      ],
      "metadata": {
        "id": "iWCWwnYiBUY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_path = join(data_dir, \"news-sample.jsonl\")\n",
        "\n",
        "raw_data = []\n",
        "for line in open(raw_data_path):\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    raw_data.append(\n",
        "        json.loads(line.strip())\n",
        "    )\n",
        "\n",
        "random.Random(101).shuffle(raw_data)\n",
        "print(f\"Raw data: {len(raw_data)}\")"
      ],
      "metadata": {
        "id": "_RBNZW5jBvVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9b07de-fe47-4fce-de14-61892812386c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw data: 2400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[0]['content']"
      ],
      "metadata": {
        "id": "lGPQ_MuwD0aS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "147095a0-b62a-4ada-9217-24ddef26503c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'يواصل المعهد العربي في باريس استقبال زواره في معرض ما تقدمه فلسطين للعالم لإطلاعهم على الإرث الثقافي والفني للفلسطينيين؛ من خلال أعمال فنية لآمالهم وصور لواقعهم الأليم تحت الاحتلال. \\n ويرى رئيس المعهد جاك لانغ -الذي أُعيد انتخابه قبل أيام للدورة الرابعة- ما يحدث في غزة حاليا جراء العدوان الإسرائيلي أنه كارثة. \\n والمعهد هو مركز ثقافي وواجهة دبلوماسية يديرها لانغ منذ 2013 ويقع على ضفة نهر السين في باريس. \\n وأشار لانغ، الذي شغل سابقا منصب وزير الثقافة بفرنسا، إلى أن المعرض هو إهداء للشعب الفلسطيني، ومُدّد ليستقبل مزيدا من الزوار حتى 31 ديسمبركانون الأول الجاري. \\n ويضم المعرض، الذي افتُتح أواخر مايوأيار الماضي، حسب لانغ العديد من المعارض الفرعية عن فلسطين وعن غزة بالتحديد، من بينها معرض الصور اليومية عن الحياة في غزة. \\n كما يشتمل على معرض الصور الفوتوكرومية القائم على تلوين صور من فلسطين تعود للقرن الـ19. \\n ويعرض الفنان الفلسطيني محمد أبو سل عملا فريدا بعنوان مترو غزة، وهو عبارة عن عمل تركيبي متعدد الوسائط، لاقى إعجابا من الزوار. \\n ويحضر الشاعر الفلسطيني الراحل محمود درويش من خلال أشعاره في أروقة المعرض، إلى جانب الكاتب والشاعر الفرنسي الملقب بعاشق فلسطين جان جينيه. \\n ومن الأعمال التي لاقت إعجاب الزوار عمل فني بعنوان بيوت غزة 2008-2009 عرضت فيه صور منازل في القطاع تدمرت بفعل القصف الإسرائيلي على غزة في 2008 و2009. \\n وقال لانغ لوكالة الأناضول أريد من المعرض أن يظهر الغنى الثقافي والإبداع لدى الشعب الفلسطيني من جميع النواحي. \\n وأشار إلى أن اسم الشعب الفلسطيني اقترن بالحرب ومن النادر أن يُسلط الضوء على ثقافته وفنه. \\n ويضم المعرض -أيضا- المتحف الفلسطيني في المنفى وأسس بالتعاون مع المؤرخ، سفير فلسطين الأسبق لدى اليونسكو إلياس صنبر. \\n ويضم تحفا تُبرع بها للمتحف لمدة 5 سنوات بإشراف المعهد العربي، وقال لانغ تعليقا على هذا المتحف نأمل أن نتمكن يوما ما من عرض هذا المتحف في القدس. \\n وبيّن لانغ أن المعرض حظي باهتمام كبير من الفرنسيين لا سيما الشباب، قائلا أريد التعريف أكثر بفلسطين، ثمة كثير من المعلومات المغلوطة حيال القضية الفلسطينية. \\n وأضاف رئيس المعهد العربي دُمّر العديد من المنازل والأحياء في غزة المعروضة صورها في المعرض. \\n وختم بالقول أعتقد أن وجود هذه الصور والأعمال هنا أمر جيد من أجل إبقاء الأمل لدى فناني غزة. \\n وكان المعهد قد أصدر كتابا جماعيا قبل شهور قليلة بعنوان ما تقدمه فلسطين للعالم، وصدر باللغة الفرنسية ضمن السلسلة الدورية عربوراما بالاشتراك مع دار النشر الفرنسية سوي Seuil. \\n ضم الكتاب مجموعة من المقالات الصحفية والدراسات الفكرية والبحوث الاجتماعية والقصائد الشعرية والصور والخرائط التوضيحية والرسومات الفنية واللوحات التشكيلية، لنخبة متميزة من الصحفيين والمفكرين والكتاب والشعراء والفنانين والرسامين والمؤرخين والباحثين العرب والأوروبيين، التي تتغنى كلها بحب سيدة الأرض فلسطين، وتحاول أن ترسم لها بالحرف والريشة صورة تتراوح بين الحلم والواقع. \\n والكتاب القيّم أسهم فيه 50 مبدعا على غرار المثقف والكاتب إلياس صنبر، والكاتبة وسفيرة فلسطين السابقة لدى اليونسكو ليلى شهيد، والمفكر والكاتب والصحفي الفرنسي المعروف آلان غريش، والكاتب والشاعر عبد اللطيف اللعبي، والفنانة التشكيلية أصالة شوك صاحبة الغلاف المميز للكتاب. \\n يحاول الكتاب أن يحفر أركيولوجيا وتاريخيا وأنثروبولوجيا وأدبيا وفنيا في مسار وطن تحوّل إلى رمز، وفكرة تحولت إلى قضية، وقضية توحّدت بشعب، وشعب فاض عن الأرض وتاه في المنفى والشتات والكون، باحثا عن صورة واقعية مطابقة لوطنه الأم المسلوب والمحاصر، فوجد نفسه في رحلة بحثه عن حق وحلم ومفتاح العودة يفتح أبوابا جديدة، ويكتشف قارات فكر بكر، ويخلق أوطانا وليدة في روحه وقلبه المتنصل من المكان والزمان والانتماء، استحضارا لصرخة الشاعر الرمز محمود درويش كل قلوب الناس جنسيتي.. فلتسقطوا عني جواز السفر. \\n يقول الكاتب كريستوف عياد في مقدمة الكتاب في الوقت الذي تبدو فيه فلسطين مهجورة من الجميع، بدءا من الدول العربية، اخترنا العودة إليها بطبيعة الحال للتحدث عن شعبها المشتت بسبب التاريخ والحدود. وأردنا مسح أراضيها المقسمة بين غزة والضفة الغربية على أن تكون القدس مركزا لا يمكن تعقبه. هذه الأراضي التي ضمها الاحتلال الإسرائيلي وابتلعها جدار الفصل العنصري. بعد أن أصبحت رمزا للاستعمار في عالم يمر بعملية إنهاء الاستعمار في النصف الثاني من القرن الـ20، فإن فلسطين لا تنتمي إلى نفسها. إنها قضية ومصدر إلهام للعالم كله. الكوفية علم الثوار في العالم، والفلسطيني لم يعد مجرد جنسية من دون دولة، بل هو رمز الرفض والانصياع والمقاومة. \\n من جانبه أشار جاك لانغ رئيس معهد العالم العربي بباريس إلى أن المعهد أراد من خلال هذا الكتاب الجماعي تقديم صورة إيجابية عن فلسطين؛ لأنه كثيرا ما يختصر الشعب الفلسطيني في النضال وفي المعاناة والحصار، ولكن يُتغافل عن الجانب الإبداعي الثقافي لهذا الشعب الذي يقدم الأفكار الجديدة المتميزة والإبداعات المتفردة إلى العالم. \\n وأشار لانغ -في حديثه السابق للجزيرة نت- إلى أن المعهد أراد أن يقدم هذا الإرث الثقافي المتميز في أبهى صورة إلى القراء، خاصة وهو يحمل قيمة كبيرة للثقافة العالمية، ومن هنا جاء عنوان الكتاب ما تقدمه فلسطين للعالم كشكل من أشكال الاعتراف بإبداعات الشعب الفلسطيني، وإضافاته الكبيرة إلى الثقافة العربية والإنسانية. \\n وأضاف الوضعية المعقدة والظلم الذي يعيشه الشعب الفلسطيني ليس وليد اليوم، وإنما هو نتيجة تراكمات تاريخية طويلة ومنذ عقود. وما يبعث على الحيرة والأسف في الوقت نفسه أننا لاحظنا هذا النسيان الدولي الذي تتعرض له القضية الفلسطينية العادلة، حتى من بعض الدول العربية نفسها. ومن هنا جاء هذا الكتاب، حتى نذكّر بهذه القضية وما يعيشه الشعب الفلسطيني من ظلم ونسيان، ونعيدها إلى مركز الأحداث والاهتمام الدولي. \\n وأشار إلى أن هذا الكتاب يحمل رسالة إلى المجتمع الدولي عن ضرورة الاعتراف بالحقوق المشروعة للشعب الفلسطيني، وأولها الحق في قيام دولة فلسطينية مستقلة. وشدد على أن المجتمع الدولي منقسم اليوم بخصوص القضية الفلسطينية، ولذلك جاء الكتاب بوصفه نوعا من الموقف والصرخة في وجه هذه المواقف المشتتة، وفي وجه الظلم الذي يتعرض له هذا الشعب، وهي صرخة تدعو المجتمع الدولي لضرورة عدم نسيان هذا الشعب المثقف المبدع والمناضل بالأفكار الأصيلة.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format Finetuning Datasets"
      ],
      "metadata": {
        "id": "xBbGFkVEH1X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sft_data_path = join(data_dir, \"sft.jsonl\")\n",
        "llm_finetunning_data = []\n",
        "\n",
        "system_message = \"\\n\".join([\n",
        "    \"You are a professional NLP data parser.\",\n",
        "    \"Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\",\n",
        "    \"Do not generate any introduction or conclusion.\"\n",
        "])\n",
        "\n",
        "for line in open(sft_data_path):\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    rec = json.loads(line.strip())\n",
        "\n",
        "    llm_finetunning_data.append({\n",
        "        \"system\": system_message,\n",
        "        \"instruction\": \"\\n\".join([\n",
        "            \"# Story:\",\n",
        "            rec[\"story\"],\n",
        "\n",
        "            \"# Task:\",\n",
        "            rec[\"task\"],\n",
        "\n",
        "            \"# Output Scheme:\",\n",
        "            rec[\"output_scheme\"],\n",
        "            \"\",\n",
        "\n",
        "            \"# Output JSON:\",\n",
        "            \"```json\"\n",
        "\n",
        "        ]),\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"\\n\".join([\n",
        "            \"```json\",\n",
        "            json.dumps(rec[\"response\"], ensure_ascii=False, default=str),\n",
        "            \"```\"\n",
        "        ]),\n",
        "        \"history\": []\n",
        "    })\n",
        "\n",
        "random.Random(101).shuffle(llm_finetunning_data)"
      ],
      "metadata": {
        "id": "bn4uUuDOIO3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(llm_finetunning_data)"
      ],
      "metadata": {
        "id": "xUXpYjfAIfKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4a553a-f8ac-4cdc-f880-cc3e08e6b974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2766"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_ds = llm_finetunning_data[:2666]\n",
        "eval_ds = llm_finetunning_data[2666:]\n",
        "\n",
        "os.makedirs(join(data_dir,\"llamafactory-finetune-data\"), exist_ok=True)\n",
        "\n",
        "with open(join(data_dir, \"llamafactory-finetune-data\", \"train.json\"), \"w\") as dest:\n",
        "    json.dump(train_ds, dest, ensure_ascii=False, default=str)\n",
        "\n",
        "with open(join(data_dir, \"llamafactory-finetune-data\", \"valdation.json\"), \"w\", encoding=\"utf8\") as dest:\n",
        "    json.dump(eval_ds, dest, ensure_ascii=False, default=str)"
      ],
      "metadata": {
        "id": "DvWmfB-QPJUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(join(data_dir, \"llamafactory-finetune-data\", \"train.json\"))\n",
        "print(join(data_dir, \"llamafactory-finetune-data\", \"valdation.json\"))"
      ],
      "metadata": {
        "id": "3mkuT7i6P6Uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f878b2-aa3b-4495-8b48-93393b367188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/llm-finetune/llamafactory-finetune-data/train.json\n",
            "/gdrive/MyDrive/llm-finetune/llamafactory-finetune-data/valdation.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##--------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "1vqHWwlwIm-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning"
      ],
      "metadata": {
        "id": "XoBc56BiRDLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Configure LLaMA-Factory for the new datasets\n",
        "\n",
        "# # update /content/LLaMA-Factory/data/dataset_info.json and append\n",
        "# ```\n",
        "   \"news_finetune_train\": {\n",
        "        \"file_name\": \"/gdrive/MyDrive/llm-finetune/llamafactory-finetune-data/train.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    },\n",
        "    \"news_finetune_val\": {\n",
        "        \"file_name\": \"/gdrive/MyDrive/llm-finetune/llamafactory-finetune-data/valdation.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    }\n",
        "# ```\n",
        "\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/apwbkni9\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/c5tf0q90"
      ],
      "metadata": {
        "id": "PMTk3i2fQKk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "OBKDlvWNY76w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n",
        "\n",
        "### model\n",
        "model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct\n",
        "trust_remote_code: true\n",
        "\n",
        "### method\n",
        "stage: sft\n",
        "do_train: true\n",
        "finetuning_type: lora\n",
        "lora_target: all\n",
        "\n",
        "lora_rank: 16\n",
        "cutoff_len: 2048\n",
        "gradient_checkpointing: true\n",
        "\n",
        "\n",
        "\n",
        "### dataset\n",
        "dataset: news_finetune_train\n",
        "eval_dataset: news_finetune_val\n",
        "template: qwen\n",
        "# max_samples: 50\n",
        "overwrite_cache: true\n",
        "preprocessing_num_workers: 16\n",
        "\n",
        "### output\n",
        "#resume_from_checkpoint: /gdrive/MyDrive/llm-finetuning/new-models/\n",
        "output_dir: /gdrive/MyDrive/llm-finetuning/new-models/\n",
        "logging_steps: 10\n",
        "save_steps: 100\n",
        "plot_loss: true\n",
        "# overwrite_output_dir: true\n",
        "\n",
        "### train\n",
        "per_device_train_batch_size: 1\n",
        "gradient_accumulation_steps: 4\n",
        "learning_rate: 1.0e-4\n",
        "num_train_epochs: 3.0\n",
        "lr_scheduler_type: cosine\n",
        "warmup_ratio: 0.1\n",
        "bf16: true\n",
        "ddp_timeout: 180000000\n",
        "\n",
        "### eval\n",
        "# val_size: 0.1\n",
        "per_device_eval_batch_size: 1\n",
        "eval_strategy: steps\n",
        "eval_steps: 100\n",
        "\n",
        "report_to: wandb\n",
        "run_name: finetune-llamafactory\n",
        "\n",
        "push_to_hub: true\n",
        "hub_model_id: \"youssef224/analyzer\"\n",
        "hub_private_repo: true\n",
        "hub_strategy: checkpoint\n"
      ],
      "metadata": {
        "id": "TCWgFdsoQrow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6e2f86-af5c-44b4-fd5c-e2cd4cc554c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd LLaMA-Factory/ && llamafactory-cli train /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml"
      ],
      "metadata": {
        "id": "Wkigp2KPVgqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6832ffe6-9a10-4d54-f653-dba0e8fa0614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-24 20:40:31.574622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758746431.595349   51045 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758746431.601610   51045 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758746431.617772   51045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758746431.617807   51045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758746431.617810   51045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758746431.617896   51045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-24 20:40:31.622805: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 09-24 20:40:40 __init__.py:190] Automatically detected platform cuda.\n",
            "[INFO|2025-09-24 20:40:42] llamafactory.hparams.parser:414 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:43,159 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:43,160 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:43,160 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:43,160 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:43,160 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:43,160 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:43,160 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2337] 2025-09-24 20:40:43,483 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|configuration_utils.py:765] 2025-09-24 20:40:44,031 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-09-24 20:40:44,032 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.56.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:44,226 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:44,226 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:44,226 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:44,226 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:44,226 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:44,226 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2068] 2025-09-24 20:40:44,226 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2337] 2025-09-24 20:40:44,538 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|2025-09-24 20:40:44] llamafactory.data.loader:143 >> Loading dataset /gdrive/MyDrive/llm-finetune/llamafactory-finetune-data/train.json...\n",
            "Converting format of dataset (num_proc=16): 100% 2666/2666 [00:00<00:00, 2692.54 examples/s]\n",
            "[INFO|2025-09-24 20:40:46] llamafactory.data.loader:143 >> Loading dataset /gdrive/MyDrive/llm-finetune/llamafactory-finetune-data/valdation.json...\n",
            "Converting format of dataset (num_proc=16): 100% 100/100 [00:00<00:00, 227.30 examples/s]\n",
            "Running tokenizer on dataset (num_proc=16): 100% 2666/2666 [00:35<00:00, 74.85 examples/s] \n",
            "training example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 6584, 451, 12567, 821, 6729, 624, 12480, 279, 3897, 1565, 6262, 63, 553, 279, 1196, 323, 279, 1565, 5097, 43781, 63, 311, 6923, 279, 1565, 5097, 4718, 18639, 5404, 537, 6923, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 198, 2, 15106, 510, 29825, 55334, 126458, 143507, 45577, 5703, 123860, 39423, 20064, 131723, 63237, 125007, 128538, 123877, 126385, 73441, 128416, 39434, 124837, 13325, 59842, 8532, 125192, 124766, 125559, 17166, 132748, 128769, 125766, 124006, 77273, 39434, 132579, 53710, 124267, 124114, 123987, 68785, 129943, 73274, 130527, 74315, 124522, 37524, 27490, 124179, 68238, 65398, 84532, 13, 715, 124766, 124283, 124543, 53479, 124322, 25871, 142734, 126655, 125007, 128305, 123877, 126385, 73441, 39434, 133498, 23364, 132137, 47632, 142734, 68785, 128248, 135638, 53479, 127172, 137499, 123877, 124636, 123890, 73441, 128562, 124006, 53479, 58656, 135430, 68785, 133950, 63415, 126385, 73441, 124265, 127467, 124080, 41593, 124636, 124072, 123904, 123963, 47632, 128405, 124837, 124082, 47632, 13, 715, 128388, 125007, 123877, 126385, 73441, 135087, 73441, 128718, 133020, 132070, 125434, 124514, 124082, 70604, 37524, 127799, 132070, 17166, 124480, 39423, 68785, 124838, 125481, 136510, 47632, 123894, 123860, 124766, 126385, 73441, 12961, 11071, 127476, 126815, 81778, 43635, 132033, 124766, 126385, 73441, 123961, 126019, 73441, 124072, 125916, 123832, 68785, 128416, 128510, 125077, 125709, 124130, 25871, 134017, 17166, 132748, 13, 715, 128827, 142201, 74315, 124522, 123961, 12653, 65398, 84532, 68785, 140880, 130283, 77703, 14558, 124346, 125143, 124226, 126350, 39434, 124104, 72804, 128305, 123877, 126385, 73441, 68785, 128259, 125027, 124009, 129919, 73274, 130151, 125637, 124678, 124476, 13325, 125646, 133843, 23224, 91344, 130519, 20931, 135542, 125701, 13, 715, 124838, 129013, 128443, 68785, 73274, 124464, 123860, 128248, 124793, 129843, 73274, 131744, 124793, 44330, 126924, 125007, 73274, 64604, 8532, 123995, 50243, 92381, 124653, 128248, 124080, 123941, 25871, 135276, 126208, 125215, 25871, 126198, 128754, 126214, 128280, 124220, 126924, 126298, 125007, 140620, 124661, 59842, 8532, 124671, 128248, 77703, 124144, 125011, 128248, 17166, 132748, 129521, 125559, 13, 715, 37524, 123860, 21360, 125313, 126899, 128707, 123862, 125653, 125007, 130616, 124261, 124220, 126924, 63237, 129193, 37524, 125657, 25871, 124665, 129636, 128259, 132338, 128636, 129581, 125490, 125108, 127930, 131351, 73441, 624, 2, 5430, 510, 2610, 614, 311, 14683, 279, 3364, 2213, 1119, 6364, 5815, 448, 264, 2265, 1119, 264, 4718, 624, 2, 9258, 43781, 510, 4913, 13193, 788, 5212, 53242, 6112, 788, 5212, 4684, 788, 330, 50, 53276, 24531, 2265, 315, 279, 3669, 3364, 10465, 330, 60992, 788, 220, 17, 20, 20, 11, 330, 1065, 4373, 788, 220, 20, 11, 330, 2102, 788, 330, 81016, 10869, 497, 330, 1313, 788, 330, 917, 14345, 330, 53242, 7495, 788, 5212, 4684, 788, 330, 81016, 2213, 315, 279, 3669, 3364, 10465, 330, 1065, 4373, 788, 220, 20, 11, 330, 2102, 788, 330, 81016, 8883, 497, 330, 1313, 788, 330, 917, 9207, 2137, 330, 6279, 788, 4383, 53242, 6112, 497, 330, 53242, 7495, 7914, 330, 2102, 788, 330, 81016, 17938, 497, 330, 1313, 788, 330, 1700, 63159, 2, 9258, 4718, 510, 73594, 2236, 151645, 198, 151644, 77091, 198, 73594, 2236, 198, 4913, 53242, 6112, 788, 330, 12087, 9975, 12566, 804, 362, 1705, 287, 52253, 18702, 497, 330, 53242, 7495, 788, 330, 78088, 3393, 14418, 702, 18683, 429, 1045, 29910, 1231, 39150, 279, 7149, 323, 4763, 315, 9842, 4152, 311, 22706, 12720, 3039, 11, 7703, 279, 5214, 315, 32688, 13, 576, 5938, 14418, 11247, 429, 1493, 29910, 2924, 6646, 58544, 3004, 11, 1741, 438, 83360, 1075, 26351, 482, 11, 438, 1632, 438, 91881, 29910, 11, 21127, 25097, 11, 323, 10923, 5859, 13, 22406, 11, 46557, 29910, 1075, 64111, 1783, 323, 3196, 3077, 5641, 49903, 11, 3654, 7912, 21025, 11, 6543, 7262, 29910, 11, 323, 59654, 323, 19754, 29910, 1231, 17040, 5322, 1393, 9842, 13, 2014, 5648, 279, 5214, 315, 32688, 11, 825, 1265, 537, 6541, 1393, 4633, 1493, 29910, 11, 5310, 979, 8266, 84084, 11, 294, 1811, 88, 11, 476, 3432, 16829, 75287, 13, 758, 4586, 11, 5489, 4633, 894, 23221, 1265, 1779, 279, 15933, 1149, 311, 1490, 421, 279, 23221, 1410, 47191, 7802, 862, 5726, 311, 6541, 21000, 13, 1084, 1265, 1083, 387, 10342, 429, 279, 18048, 315, 264, 23221, 916, 279, 5546, 1558, 537, 3076, 432, 702, 902, 3108, 6239, 1189, 532, 73594, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a professional NLP data parser.\n",
            "Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "# Story:\n",
            "حذرت مجلة فاينانس تست من أن بعض الأدوية قد تهدد سلامة وأمان القيادة لتسببها في تأخر ردة الفعل، مما يرفع خطر وقوع حادث. \n",
            " وأوضحت المجلة الألمانية أن هذه الأدوية تشمل مسكنات الألم، على سبيل المثال المواد الأفيونية ومنها المورفين، وكذلك أدوية الصداع النصفي والمنومات والمهدئات. \n",
            " كما أن الأدوية النفسية مثل مضادات الاكتئاب ومضادات الذهان، وبعض قطرات العين وأدوية ارتفاع ضغط الدم وأدوية الحساسية والسكري، قد تمثل مشكلة أثناء القيادة. \n",
            " ولتجنب خطر الحوادث، ينبغي عدم قيادة السيارة عند تناول هذه الأدوية، لا سيما عندما يشعر المرء بالدوار والنعاس وضعف التركيز. \n",
            " وبشكل عام، يتعين على أي شخص يتناول أي دواء أن يُلقي نظرة على النشرة الداخلية لمعرفة ما إذا كان هذا الدواء يمكن أن يؤثر سلبا على قدرته على القيادة بأمان. \n",
            " وينبغي أيضا مراعاة أن توفر الدواء من دون وصفة طبية لا يعني أنه ليس له آثار جانبية.\n",
            "# Task:\n",
            "You have to translate the story content into English associated with a title into a JSON.\n",
            "# Output Scheme:\n",
            "{\"properties\": {\"translated_title\": {\"description\": \"Suggested translated title of the news story.\", \"maxLength\": 255, \"minLength\": 5, \"title\": \"Translated Title\", \"type\": \"string\"}, \"translated_content\": {\"description\": \"Translated content of the news story.\", \"minLength\": 5, \"title\": \"Translated Content\", \"type\": \"string\"}}, \"required\": [\"translated_title\", \"translated_content\"], \"title\": \"TranslatedStory\", \"type\": \"object\"}\n",
            "\n",
            "# Output JSON:\n",
            "```json<|im_end|>\n",
            "<|im_start|>assistant\n",
            "```json\n",
            "{\"translated_title\": \"Warning About Medications Affecting Driving Safety\", \"translated_content\": \"Finance Test magazine has warned that some medications may threaten the safety and security of driving due to delayed reaction times, increasing the risk of accidents. The German magazine explained that these medications include pain relievers, such as opioids like morphine, as well as migraine medications, sleeping pills, and sedatives. Additionally, psychiatric medications like antidepressants and antipsychotics, certain eye drops, blood pressure medications, and allergy and diabetes medications may pose problems while driving. To avoid the risk of accidents, one should not drive while taking these medications, especially when feeling dizzy, drowsy, or having difficulty concentrating. In general, anyone taking any medication should check the leaflet to see if the medication could negatively affect their ability to drive safely. It should also be noted that the availability of a medication over the counter does not mean it has no side effects.\"}\n",
            "```<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 198, 4913, 53242, 6112, 788, 330, 12087, 9975, 12566, 804, 362, 1705, 287, 52253, 18702, 497, 330, 53242, 7495, 788, 330, 78088, 3393, 14418, 702, 18683, 429, 1045, 29910, 1231, 39150, 279, 7149, 323, 4763, 315, 9842, 4152, 311, 22706, 12720, 3039, 11, 7703, 279, 5214, 315, 32688, 13, 576, 5938, 14418, 11247, 429, 1493, 29910, 2924, 6646, 58544, 3004, 11, 1741, 438, 83360, 1075, 26351, 482, 11, 438, 1632, 438, 91881, 29910, 11, 21127, 25097, 11, 323, 10923, 5859, 13, 22406, 11, 46557, 29910, 1075, 64111, 1783, 323, 3196, 3077, 5641, 49903, 11, 3654, 7912, 21025, 11, 6543, 7262, 29910, 11, 323, 59654, 323, 19754, 29910, 1231, 17040, 5322, 1393, 9842, 13, 2014, 5648, 279, 5214, 315, 32688, 11, 825, 1265, 537, 6541, 1393, 4633, 1493, 29910, 11, 5310, 979, 8266, 84084, 11, 294, 1811, 88, 11, 476, 3432, 16829, 75287, 13, 758, 4586, 11, 5489, 4633, 894, 23221, 1265, 1779, 279, 15933, 1149, 311, 1490, 421, 279, 23221, 1410, 47191, 7802, 862, 5726, 311, 6541, 21000, 13, 1084, 1265, 1083, 387, 10342, 429, 279, 18048, 315, 264, 23221, 916, 279, 5546, 1558, 537, 3076, 432, 702, 902, 3108, 6239, 1189, 532, 73594, 151645, 198]\n",
            "labels:\n",
            "```json\n",
            "{\"translated_title\": \"Warning About Medications Affecting Driving Safety\", \"translated_content\": \"Finance Test magazine has warned that some medications may threaten the safety and security of driving due to delayed reaction times, increasing the risk of accidents. The German magazine explained that these medications include pain relievers, such as opioids like morphine, as well as migraine medications, sleeping pills, and sedatives. Additionally, psychiatric medications like antidepressants and antipsychotics, certain eye drops, blood pressure medications, and allergy and diabetes medications may pose problems while driving. To avoid the risk of accidents, one should not drive while taking these medications, especially when feeling dizzy, drowsy, or having difficulty concentrating. In general, anyone taking any medication should check the leaflet to see if the medication could negatively affect their ability to drive safely. It should also be noted that the availability of a medication over the counter does not mean it has no side effects.\"}\n",
            "```<|im_end|>\n",
            "\n",
            "Running tokenizer on dataset (num_proc=16): 100% 100/100 [00:11<00:00,  8.57 examples/s]\n",
            "eval example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 6584, 451, 12567, 821, 6729, 624, 12480, 279, 3897, 1565, 6262, 63, 553, 279, 1196, 323, 279, 1565, 5097, 43781, 63, 311, 6923, 279, 1565, 5097, 4718, 18639, 5404, 537, 6923, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 198, 2, 15106, 510, 124839, 124346, 124058, 123987, 126655, 131549, 124104, 16157, 39434, 124446, 5994, 128504, 128464, 128510, 125077, 130995, 25871, 50243, 125603, 133427, 20064, 124966, 138567, 141912, 124872, 17166, 123862, 126880, 73441, 13, 48426, 39434, 125150, 136521, 56794, 39697, 123829, 123832, 124006, 130995, 47632, 59842, 124075, 29825, 73441, 126492, 13325, 125192, 138829, 124678, 5703, 63237, 53479, 124333, 125013, 123961, 125248, 73441, 68785, 124072, 127558, 23224, 47632, 17166, 126089, 73441, 124012, 55334, 125275, 128252, 53479, 69682, 31073, 137159, 124265, 79820, 124061, 125006, 123938, 125165, 128405, 81778, 49388, 125815, 53479, 126751, 125168, 129353, 63415, 125933, 124012, 127322, 124072, 32790, 123920, 43635, 124082, 124072, 124887, 31382, 124072, 124449, 93543, 47632, 13, 715, 124838, 141014, 134430, 126195, 39434, 124851, 95198, 47632, 31073, 68785, 39434, 124126, 92381, 124335, 77273, 136521, 43982, 124525, 25871, 74315, 125248, 98719, 39434, 81778, 137690, 27846, 129569, 21360, 128259, 39434, 64604, 124829, 55057, 13, 715, 129919, 73274, 124552, 124269, 126504, 77273, 85153, 124438, 125197, 72804, 68785, 73274, 125203, 95975, 13325, 63415, 125750, 132879, 128248, 82168, 127322, 130208, 98719, 127640, 47632, 68785, 139361, 91335, 5703, 220, 24, 128476, 131723, 125267, 124138, 63415, 32790, 132568, 53479, 124176, 124412, 5703, 136421, 73441, 125616, 126925, 124282, 129521, 39697, 16157, 35038, 124006, 53479, 127221, 25871, 138829, 124678, 5703, 63237, 130777, 23364, 35038, 20064, 124340, 55334, 35038, 13, 715, 128295, 129806, 128252, 55891, 124035, 129899, 125572, 125646, 77273, 53710, 127896, 23364, 10176, 124464, 25871, 128248, 23364, 124706, 43982, 21360, 73771, 124226, 135745, 135512, 68785, 37524, 124425, 72804, 77273, 52157, 125646, 23224, 82168, 39697, 93543, 124787, 27846, 124623, 125067, 65398, 5703, 124821, 124533, 123897, 65398, 5703, 124147, 124421, 128885, 63237, 68238, 126703, 125637, 58656, 124821, 124009, 63237, 128773, 82168, 127322, 127640, 47632, 130777, 25871, 68785, 37524, 130741, 124079, 126195, 126815, 81778, 126925, 131359, 77273, 132879, 132875, 128131, 13, 715, 136837, 123978, 128587, 31073, 124476, 124341, 126406, 123862, 124476, 125592, 124009, 31073, 124663, 124641, 125168, 128261, 129106, 12961, 41593, 125903, 65398, 124006, 77273, 133020, 128473, 17166, 124697, 127065, 58656, 133020, 128473, 85153, 124438, 125197, 72804, 68785, 129673, 77273, 23364, 136378, 133114, 123897, 79820, 128248, 124665, 123940, 39697, 53479, 126236, 39423, 25871, 137702, 133205, 47632, 124072, 125592, 124009, 31073, 126196, 125007, 81778, 49388, 125867, 124142, 27490, 55057, 142327, 124671, 68785, 128474, 94957, 127029, 125006, 136174, 77273, 129289, 124114, 11798, 65398, 27490, 17166, 124697, 124787, 31073, 124265, 81778, 124872, 129632, 136310, 128773, 128631, 124079, 124267, 13, 715, 27846, 126433, 23364, 127897, 124006, 126926, 126113, 37524, 32790, 123920, 43635, 124082, 124006, 125358, 124223, 25871, 68785, 125857, 125859, 125007, 126490, 124075, 82168, 129132, 123938, 125040, 124011, 136521, 27846, 20931, 124343, 128248, 59842, 124363, 128412, 86941, 33090, 124282, 56794, 133227, 124181, 124209, 124330, 124082, 128248, 124665, 72804, 123913, 124210, 8532, 126249, 124124, 125006, 123832, 124636, 128168, 135542, 73441, 68785, 37524, 124880, 14293, 124343, 129521, 127274, 128912, 63237, 52157, 123920, 43635, 124082, 129726, 123877, 127322, 27490, 77273, 125547, 13, 715, 37524, 143500, 124422, 5703, 63237, 128443, 220, 17, 15, 17, 18, 68785, 134842, 220, 17, 18, 16, 52157, 124330, 124082, 5703, 63237, 63415, 124224, 220, 20, 20, 16, 52157, 124330, 124082, 5703, 68238, 124291, 80970, 128248, 129726, 123877, 127322, 27490, 77273, 136521, 68785, 124072, 124363, 127818, 27846, 33090, 69423, 25871, 137010, 126455, 125960, 126510, 132294, 126483, 93543, 125273, 125192, 68785, 128248, 124665, 72804, 59842, 124210, 8532, 125007, 126490, 124075, 13, 715, 139400, 124326, 84532, 130574, 124269, 124014, 73441, 123913, 124210, 124653, 124072, 137917, 124172, 79820, 124325, 77273, 27846, 47632, 35038, 5703, 128252, 124209, 123920, 43635, 124082, 124114, 35244, 124325, 56794, 129132, 128842, 125110, 72804, 20931, 124072, 127558, 23224, 47632, 125616, 13325, 125192, 123961, 123829, 125320, 128248, 52157, 16157, 124346, 82168, 14558, 39434, 14558, 85153, 20064, 125027, 11911, 3540, 77273, 131478, 27846, 95198, 126300, 68785, 39434, 125150, 125007, 126490, 124075, 23364, 80970, 124169, 59842, 124210, 123897, 5703, 23364, 131981, 124009, 125006, 131610, 13, 715, 132294, 128349, 68785, 139869, 129286, 82168, 12653, 124190, 25871, 94957, 124128, 77273, 125007, 126490, 124075, 128420, 52157, 124330, 124082, 86941, 134331, 31382, 124787, 133965, 128763, 84532, 125275, 37524, 129215, 74315, 8532, 125275, 39434, 130510, 77273, 131865, 23364, 124335, 125089, 129890, 125829, 68785, 128641, 124147, 124284, 73441, 125709, 124837, 23364, 16157, 124533, 56794, 124887, 31382, 27846, 123980, 126789, 8532, 126698, 124209, 124642, 124061, 13, 715, 128641, 86941, 124421, 124142, 68785, 131052, 132450, 14558, 123961, 41593, 123860, 124072, 21360, 79820, 23224, 77273, 125007, 126490, 124075, 68785, 59842, 124880, 124128, 69682, 138194, 127837, 124476, 23224, 132695, 128248, 74315, 8532, 127069, 125040, 125924, 25871, 126196, 63237, 41593, 47632, 92072, 124343, 73441, 124665, 126504, 73441, 68785, 129308, 23364, 84532, 125756, 56794, 131248, 68238, 125225, 52157, 124223, 124072, 124125, 129215, 27846, 33090, 125646, 125637, 132791, 132450, 14558, 13, 715, 128295, 129806, 129968, 128252, 17166, 127029, 47632, 124080, 126409, 125165, 56794, 139206, 53710, 31073, 124495, 124695, 123920, 33090, 77273, 136521, 68785, 128288, 63237, 63415, 130434, 32790, 47632, 14558, 56794, 139206, 124666, 123860, 13325, 59842, 93543, 20931, 77273, 131478, 85153, 125737, 93543, 68785, 124766, 31073, 124075, 128831, 53710, 124075, 127187, 53710, 31073, 124495, 53479, 124146, 124476, 126077, 123920, 29825, 125249, 123862, 73441, 77273, 131478, 129435, 81778, 80970, 13, 128388, 125007, 63237, 124330, 27490, 53710, 124394, 5703, 124476, 131378, 63237, 85153, 124438, 125197, 72804, 68785, 128252, 131351, 134499, 127219, 124766, 58656, 126385, 68785, 39434, 137469, 39423, 130639, 124218, 124006, 130245, 27846, 139206, 124666, 123860, 13325, 59842, 93543, 20931, 13, 715, 39434, 39697, 124343, 130632, 85153, 125737, 93543, 125040, 126907, 136521, 27846, 127029, 47632, 53710, 124394, 73441, 23364, 84532, 124872, 63237, 139894, 124006, 125007, 39434, 126666, 53710, 124552, 125492, 128259, 39434, 64604, 124829, 55057, 13, 45577, 134465, 125007, 50243, 125962, 131865, 124006, 141757, 77273, 142760, 124325, 130259, 125993, 55057, 123913, 124075, 29825, 73441, 135745, 128443, 123860, 128546, 14293, 124421, 123860, 68785, 68238, 124641, 14293, 77703, 123832, 129756, 27846, 93543, 129119, 37524, 131112, 123860, 20064, 128248, 85153, 32790, 124346, 43982, 124839, 73441, 63237, 63237, 92381, 124325, 123913, 124075, 124290, 142352, 130579, 132067, 129040, 56794, 137121, 128920, 124476, 137488, 128248, 94957, 11071, 124352, 17166, 123832, 124636, 68785, 37524, 136908, 130555, 47632, 137387, 68785, 128293, 124676, 123980, 124663, 126992, 125110, 126687, 13, 715, 37524, 127853, 23224, 27846, 93543, 129119, 77273, 129289, 128773, 17166, 69423, 125691, 74315, 41593, 133378, 77273, 136521, 68785, 129308, 12961, 124514, 32790, 95975, 125069, 27490, 127224, 50243, 125808, 140701, 43982, 125126, 73274, 10176, 125645, 128252, 220, 20, 142525, 128443, 68785, 134157, 128252, 52157, 125646, 23224, 124006, 124012, 125676, 25871, 128405, 39697, 131101, 27846, 142775, 59842, 127297, 124085, 73441, 37524, 23224, 134723, 73441, 133114, 123897, 130935, 13, 715, 63237, 50243, 124210, 73441, 129446, 68785, 39434, 33090, 14293, 55334, 21360, 131478, 59842, 93543, 123860, 20064, 27846, 20064, 124925, 124006, 131216, 125572, 125646, 68785, 128476, 39434, 133259, 27846, 124223, 5703, 124218, 124006, 123894, 134723, 73441, 124147, 32790, 129636, 124269, 123829, 124511, 13, 715, 131247, 27846, 64604, 124079, 220, 16, 20, 136574, 129346, 124476, 124142, 124226, 63237, 130632, 63415, 124434, 20064, 132450, 73441, 68785, 130616, 124261, 59842, 93543, 123860, 20064, 23364, 80970, 124169, 23364, 127172, 124075, 125006, 124223, 95975, 127116, 126249, 124210, 84532, 123860, 126195, 126502, 124917, 39434, 125839, 23364, 8532, 124138, 25871, 13, 715, 125027, 125510, 127072, 95975, 132280, 126249, 124210, 84532, 123890, 126195, 125993, 55057, 53479, 123897, 125165, 124476, 20064, 124925, 141279, 125007, 124434, 124138, 77273, 63237, 124641, 8532, 132319, 63237, 39434, 35038, 128559, 123897, 92072, 126009, 124075, 68785, 37524, 123938, 124787, 39697, 27846, 69423, 141125, 68785, 128402, 41593, 125346, 55057, 82611, 129637, 86941, 70604, 65398, 125067, 124075, 68785, 124766, 58656, 125559, 5703, 125007, 126490, 124075, 13, 715, 133114, 20931, 82168, 127472, 86941, 47632, 124347, 68785, 124476, 131378, 63237, 130632, 53710, 125701, 5703, 68785, 52157, 124642, 124267, 128248, 43982, 92381, 124325, 124663, 123938, 124511, 68785, 128476, 39434, 33090, 55334, 21360, 43982, 32790, 124181, 125100, 126924, 17166, 129801, 129006, 125263, 13, 140676, 68785, 39434, 125645, 129152, 123877, 140614, 125100, 65398, 124653, 129353, 17166, 69423, 125691, 17166, 124179, 124653, 68785, 134939, 126731, 125629, 17166, 124449, 93543, 47632, 124012, 123897, 130935, 126249, 124124, 43982, 92381, 124325, 124172, 132067, 124209, 124642, 124061, 13, 128252, 131351, 128280, 127763, 124511, 124663, 126504, 73441, 68785, 39434, 125150, 123961, 41593, 123890, 132450, 73441, 37524, 130763, 124172, 12653, 95975, 8532, 124172, 79820, 124325, 68785, 124838, 129154, 124075, 129072, 129395, 93543, 123877, 124438, 125729, 68785, 126208, 124290, 126195, 129745, 123894, 125126, 125006, 123904, 127087, 13, 715, 39434, 123904, 128074, 124209, 124421, 16157, 47632, 124147, 32790, 129636, 127955, 123941, 25871, 128248, 55891, 57859, 70604, 143700, 49388, 123897, 55891, 124985, 123860, 68785, 128248, 12961, 11071, 127476, 77703, 124144, 16157, 131261, 5703, 23364, 124015, 135726, 59842, 43635, 29825, 131010, 68785, 56794, 130059, 47632, 55891, 130831, 68238, 127347, 73441, 63237, 125547, 133460, 129119, 13, 715, 140677, 43982, 123993, 124326, 35038, 128559, 126277, 141279, 68785, 128307, 129106, 68238, 130248, 16157, 63237, 136719, 124552, 128476, 73274, 129327, 55057, 124080, 124552, 128953, 141755, 129996, 82168, 55334, 124179, 123877, 32790, 132568, 126913, 124387, 25871, 68785, 45577, 57859, 80970, 126195, 125867, 125750, 133057, 128660, 23364, 125089, 33090, 56794, 124762, 55334, 63237, 124012, 124545, 125621, 129992, 124072, 39697, 124187, 25871, 37524, 13325, 127347, 125621, 124653, 68785, 128660, 63237, 123877, 43635, 23224, 124325, 137387, 139744, 128261, 128875, 81778, 123832, 43982, 32790, 124181, 124663, 126992, 13, 48426, 39434, 130510, 131478, 129517, 124142, 79820, 5703, 124172, 79820, 124325, 137855, 82168, 127472, 124665, 58656, 125463, 139981, 137450, 68785, 128293, 57859, 124636, 59842, 124925, 127837, 74315, 124291, 5703, 82611, 124675, 124422, 124006, 131478, 17166, 124449, 93543, 47632, 27846, 127328, 124075, 39697, 77273, 136521, 68785, 129308, 82168, 12653, 124190, 25871, 23364, 127534, 73441, 39434, 136204, 63237, 73274, 143516, 124006, 13, 715, 128510, 125645, 128305, 125088, 127877, 11071, 124663, 126504, 73441, 126249, 79820, 124511, 129353, 23364, 125837, 125007, 126490, 124075, 126530, 20064, 83827, 124917, 124838, 58656, 129345, 68785, 128293, 133259, 128763, 127060, 53710, 123829, 124511, 63237, 17166, 124449, 93543, 47632, 68785, 131863, 129431, 124665, 70604, 23224, 16157, 131216, 128307, 128259, 23364, 84532, 95198, 125490, 13, 715, 39434, 124787, 29825, 136521, 56794, 124712, 123938, 39434, 123993, 27490, 124012, 127472, 133407, 74315, 14558, 124669, 23364, 140080, 25871, 68785, 129673, 27846, 126070, 128773, 63237, 220, 21, 15, 77703, 124325, 73274, 20931, 124085, 43982, 125123, 124006, 220, 18, 142525, 23364, 124015, 13, 128306, 123997, 124868, 82168, 124214, 125108, 81778, 123832, 82168, 124214, 63415, 11071, 124669, 128631, 123993, 27490, 123860, 53479, 135417, 126610, 27846, 125821, 125011, 142822, 131829, 68785, 129308, 73594, 2236, 198, 4913, 26485, 6112, 788, 330, 124341, 31073, 32790, 95975, 82168, 125291, 136521, 25, 130995, 47632, 59842, 124075, 29825, 73441, 126492, 13325, 125192, 37524, 129569, 21360, 128259, 39434, 64604, 124829, 55057, 497, 330, 26485, 51354, 788, 4383, 125650, 124075, 497, 330, 31382, 20064, 124075, 124290, 125616, 13325, 125192, 497, 330, 91962, 124438, 125197, 72804, 497, 330, 124229, 126490, 124075, 497, 330, 124839, 81778, 49388, 125815, 7914, 330, 26485, 27251, 788, 4383, 129352, 136521, 130995, 47632, 59842, 124075, 29825, 73441, 126492, 13325, 125192, 23364, 137337, 25871, 10465, 330, 14293, 46586, 125267, 82168, 127322, 130208, 98719, 125572, 125646, 27846, 126047, 132568, 53479, 124176, 124412, 5703, 136421, 73441, 10465, 330, 124229, 126490, 124075, 140118, 82168, 124282, 56794, 133227, 124181, 124209, 124330, 124082, 10465, 330, 91962, 125737, 93543, 129375, 57859, 11798, 77703, 129538, 59842, 124075, 29825, 73441, 125857, 125859, 128248, 94957, 11071, 124352, 10465, 330, 129352, 136521, 74315, 14558, 124669, 53710, 123829, 124511, 56794, 124712, 123938, 53479, 81778, 49388, 125815, 1189, 1125, 330, 26485, 11847, 788, 330, 31382, 20064, 124075, 124290, 497, 330, 26485, 47377, 788, 61753, 2996, 3142, 788, 330, 125650, 124075, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 91962, 124438, 125197, 72804, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 124229, 126490, 124075, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 91962, 125737, 93543, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 124833, 11071, 130208, 98719, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 127799, 128473, 17166, 124697, 127065, 58656, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 126628, 35038, 5703, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 129989, 123860, 20064, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 124887, 31382, 86941, 47632, 124347, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 32790, 39423, 123897, 63415, 58656, 126267, 497, 330, 2996, 1819, 788, 330, 2527, 9207, 23439, 73594, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a professional NLP data parser.\n",
            "Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "# Story:\n",
            "المادة الإعلانية أدناه تخص Go Türkiye ولا تمثل وجهة نظر مؤسسة شبكة الجزيرة الاعلامية. \n",
            "  \n",
            " تقدم تركيا لزائريها وجهات سياحية مستدامة بدءا من المحميات الحضرية، والمنتجعات الريفية الجذابة إلى المأكولات الصديقة للبيئة والمغامرات المبهجة عبر أروع الجزر والشواطئ والجبال والبحيرات. \n",
            " وبغض النظر عن تفضيلاتك، تنتظرك في تركيا عطلة خضراء تغمرك بتجارب لا تُنسى. \n",
            " عندما يحل الربيع في إسطنبول، يتوافد أهل المدينة على جزر الأمراء الأميرات، وعددها 9 حيث تستقبلهم أشجار الميموزا الذهبية المستوطنة بأزهارها الملونة بدءا من شهر مارسآذار. \n",
            " انضم إلى هؤلاء الزوار في رحلة ممتعة على متن عبّارة لمدة ساعة، وتجول في شوارع جزيرتي بويوكادا وهيبليادا الخاليتين من حركة المرور وهما من أكثر جزر الأميرات شهرة، وابتعد عن ضغوط الحياة في المدينة العملاقة. \n",
            " اختتم يومك بالاستمتاع بالأسماك الطازجة التي يتم اصطيادها في مضيق البوسفور مضيق إسطنبول، وذلك في مطعم تقليدي على طراز الميهانة يقدم المقبلات والأسماك مع أنغام الموسيقى غالبا، قبل التوجه للإقامة في أحد الفنادق البوتيك الصغيرة ذات خدمات أكثر المتعددة. \n",
            " بفضل مياهها البلورية وشواطئها المشمسة، تحافظ أنطاليا جنوبي غرب تركيا بفخر على سمعتها كجنة لعشاق الشاطئ على طول الساحل البكر للريفييرا التركية، وتفتخر بأكبر عدد من شواطئ العلم الأزرق في العالم. \n",
            " واعتبارا من عام 2023، يوجد 231 شاطئا من أصل 551 شاطئا حاصلا على العلم الأزرق في تركيا، والمعروف بجودة المياه الاستثنائية ومعايير السلامة، على طول ساحل أنطاليا. \n",
            " فمن الكثبان الرملية الساحرة والآثار القديمة في باتارا إلى الشواطئ الفخمة لنوادي الغولف والمنتجعات المستدامة الحائزة على شهادة جي تي إس سي GTSC في منطقة بيليك، تقدم أنطاليا ملاذا ساحليا مصمما للجميع. \n",
            " ومع ذلك، ربما تكون جوهرة التاج في أنطاليا هي شاطئ كونيالتي فهو بمثابة واحة خلابة تقع في مكان مركزي بالمدينة، وفي الخلفية مشهد مهيب لجبال بيداغلاري الشاهقة. \n",
            " وفي كاليسي، المركز التاريخي الحصين والبديع في أنطاليا، ستفاجأ أيضًا بالعثور على خلجان غريبة مع منصات صخرية طبيعية، وهي مثالية لأخذ حمام شمس والسباحة بجوار المرسى التاريخي. \n",
            " انضم الآن إلى الوجهات الناشئة لرياضة ركوب الأمواج في تركيا، كل من ألاتشاتي لرياضة الويند سيرف في منطقة إزمير، وأكياكا رياضة ركوب الموج بالألواح الشراعية في منطقة موغلا. كما أن مناطق ريفا بالقرب من إسطنبول، إلى جانب ألانيا وأوردو، تطوران أماكنها الخاصة برياضة الويند سيرف. \n",
            " تزخر مدينة إزمير غربي تركيا بوجهات ريفية مثيرة من شأنها أن تجعل رحلتك لا تُنسى. فبعد أن نالت مكانها الصحيح في قائمة أفضل القرى السياحية لمدة عامين متتاليين، حازت قريتا بيرجي وشيرينس على إشادة عالمية من منظمة السياحة التابعة للأمم المتحدة لالتزامهما بالحفاظ على التراث الريفي، ورعاية المجتمعات المحلية، وتقاليد الطهي الغنية. \n",
            " وتقع بيرجي في أحد أكثر الوديان خصوبة في تركيا، وهي اكتشاف ثقافي نادر بتاريخ عريق يمتد إلى 5 آلاف عام، بالإضافة إلى شوارعها الجميلة والمزينة بمنازل سلجوقية وعثمانية تقليدية. \n",
            " من ناحية أخرى، تجتذب منطقة سيرينس بسحرها الخاص الزوار، حيث تتميز بمساكنها العثمانية الخشبية الرائعة. \n",
            " وعلى بُعد 15 دقيقة فقط بالسيارة من مدينة أفسس التاريخية، توفر سيرينس ملاذا مثاليا للمسافرين الباحثين عن محطة توقف ملهمة. \n",
            " سيجد المسافرون الباحثون عن القرى المليئة بالسحر المحلي أنفسهم في منازل بكل من تاراكلي صقاريا، وبيتيز بودروم، ومصطفى باشا كابادوكيا، وأورمانا أنطاليا. \n",
            " تقف جبال كاتشار، بالقرب من مدينة ريزا، شاهدة على عظمة الطبيعة، حيث تجذب عشاق الهواء الطلق والتاريخ. وهنا، تتدفق الأنهار الهادرة عبر الوديان الوعرة، بينما تعكس البحيرات الجليدية البكر عظمة القمم الشاهقة. إلى جانب هذا الروعة الطبيعية، تقدم الحصون التاريخية وطرق القوافل القديمة، وبقايا طريق الحرير الأسطوري، لمحة عن الماضي العريق للمنطقة. \n",
            " تمنحك الشاليهات الخشبية المنتشرة على هضاب تشاملي همشين، على ارتفاع قدره ألفا متر فوق سطح البحر، لحظات هروب حقيقية من العالم الخارجي. \n",
            " وهناك عسل الكاراكوان المحلي، الذي يتم حصاده من المناحل حيث يرعى النحل بشكل طبيعي داخل جذوع الأشجار المجوفة، فضلا عن الموهلاما وهو مزيج لذيذ من الجبن الذائب والزبدة ودقيق الذرة، وهو من الأطعمة المحلية الأساسية التي ستغري عشاق الطهي. \n",
            "  \n",
            " تقع منطقة بيسيديا القديمة شمال جبال طوروس الغربية مباشرة، وتضفي سحرًا خاصا باعتبارها منطقة البحيرات بامتياز في تركيا، وهي جوهرة مخفية تنتظر من يكتشفها. \n",
            " تمتد هذه المناظر الطبيعية البديعة عبر مدن أنطاليا وإسبرطة وبوردور، وتتميز بمجموعة رائعة من البحيرات، لكل منها طابعه الخاص الذي لا مثيل له. \n",
            " تتيح تركيا لمحبي تسلق الجبال عدة خيارات ممتازة، وذلك بوجود أكثر من 60 قمة يفوق علوها 3 آلاف متر. ويتحدى جبل آغري جبل أرارات المتسلقين المخضرمين بقمته المهيبة، وهي```json\n",
            "{\"story_title\": \"استكشاف جمال تركيا: وجهات سياحية مستدامة وتجارب لا تُنسى\", \"story_keywords\": [\"تركيا\", \"السياحة المستدامة\", \"إسطنبول\", \"أنطاليا\", \"المغامرات\"], \"story_summary\": [\"تقدم تركيا وجهات سياحية مستدامة متنوعة.\", \"تستقبل جزر الأمراء الزوار بأشجار الميموزا الذهبية.\", \"أنطاليا تعتبر جنة لعشاق الشاطئ.\", \"إزمير تحتضن قرى سياحية تحافظ على التراث.\", \"تقدم تركيا خيارات رائعة لمحبي المغامرات.\"], \"story_category\": \"السياحة\", \"story_entities\": [{\"entity_value\": \"تركيا\", \"entity_type\": \"location\"}, {\"entity_value\": \"إسطنبول\", \"entity_type\": \"location\"}, {\"entity_value\": \"أنطاليا\", \"entity_type\": \"location\"}, {\"entity_value\": \"إزمير\", \"entity_type\": \"location\"}, {\"entity_value\": \"جزر الأمراء\", \"entity_type\": \"location\"}, {\"entity_value\": \"مضيق البوسفور\", \"entity_type\": \"location\"}, {\"entity_value\": \"باتارا\", \"entity_type\": \"location\"}, {\"entity_value\": \"سيرينس\", \"entity_type\": \"location\"}, {\"entity_value\": \"جبال كاتشار\", \"entity_type\": \"location\"}, {\"entity_value\": \"شانلي أورفا\", \"entity_type\": \"location\"}]}\n",
            "```<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 198, 4913, 26485, 6112, 788, 330, 124341, 31073, 32790, 95975, 82168, 125291, 136521, 25, 130995, 47632, 59842, 124075, 29825, 73441, 126492, 13325, 125192, 37524, 129569, 21360, 128259, 39434, 64604, 124829, 55057, 497, 330, 26485, 51354, 788, 4383, 125650, 124075, 497, 330, 31382, 20064, 124075, 124290, 125616, 13325, 125192, 497, 330, 91962, 124438, 125197, 72804, 497, 330, 124229, 126490, 124075, 497, 330, 124839, 81778, 49388, 125815, 7914, 330, 26485, 27251, 788, 4383, 129352, 136521, 130995, 47632, 59842, 124075, 29825, 73441, 126492, 13325, 125192, 23364, 137337, 25871, 10465, 330, 14293, 46586, 125267, 82168, 127322, 130208, 98719, 125572, 125646, 27846, 126047, 132568, 53479, 124176, 124412, 5703, 136421, 73441, 10465, 330, 124229, 126490, 124075, 140118, 82168, 124282, 56794, 133227, 124181, 124209, 124330, 124082, 10465, 330, 91962, 125737, 93543, 129375, 57859, 11798, 77703, 129538, 59842, 124075, 29825, 73441, 125857, 125859, 128248, 94957, 11071, 124352, 10465, 330, 129352, 136521, 74315, 14558, 124669, 53710, 123829, 124511, 56794, 124712, 123938, 53479, 81778, 49388, 125815, 1189, 1125, 330, 26485, 11847, 788, 330, 31382, 20064, 124075, 124290, 497, 330, 26485, 47377, 788, 61753, 2996, 3142, 788, 330, 125650, 124075, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 91962, 124438, 125197, 72804, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 124229, 126490, 124075, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 91962, 125737, 93543, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 124833, 11071, 130208, 98719, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 127799, 128473, 17166, 124697, 127065, 58656, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 126628, 35038, 5703, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 129989, 123860, 20064, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 124887, 31382, 86941, 47632, 124347, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 32790, 39423, 123897, 63415, 58656, 126267, 497, 330, 2996, 1819, 788, 330, 2527, 9207, 23439, 73594, 151645, 198]\n",
            "labels:\n",
            "```json\n",
            "{\"story_title\": \"استكشاف جمال تركيا: وجهات سياحية مستدامة وتجارب لا تُنسى\", \"story_keywords\": [\"تركيا\", \"السياحة المستدامة\", \"إسطنبول\", \"أنطاليا\", \"المغامرات\"], \"story_summary\": [\"تقدم تركيا وجهات سياحية مستدامة متنوعة.\", \"تستقبل جزر الأمراء الزوار بأشجار الميموزا الذهبية.\", \"أنطاليا تعتبر جنة لعشاق الشاطئ.\", \"إزمير تحتضن قرى سياحية تحافظ على التراث.\", \"تقدم تركيا خيارات رائعة لمحبي المغامرات.\"], \"story_category\": \"السياحة\", \"story_entities\": [{\"entity_value\": \"تركيا\", \"entity_type\": \"location\"}, {\"entity_value\": \"إسطنبول\", \"entity_type\": \"location\"}, {\"entity_value\": \"أنطاليا\", \"entity_type\": \"location\"}, {\"entity_value\": \"إزمير\", \"entity_type\": \"location\"}, {\"entity_value\": \"جزر الأمراء\", \"entity_type\": \"location\"}, {\"entity_value\": \"مضيق البوسفور\", \"entity_type\": \"location\"}, {\"entity_value\": \"باتارا\", \"entity_type\": \"location\"}, {\"entity_value\": \"سيرينس\", \"entity_type\": \"location\"}, {\"entity_value\": \"جبال كاتشار\", \"entity_type\": \"location\"}, {\"entity_value\": \"شانلي أورفا\", \"entity_type\": \"location\"}]}\n",
            "```<|im_end|>\n",
            "\n",
            "[INFO|configuration_utils.py:765] 2025-09-24 20:41:36,871 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-09-24 20:41:36,872 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.56.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|2025-09-24 20:41:36] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
            "[WARNING|logging.py:328] 2025-09-24 20:41:37,378 >> `torch_dtype` is deprecated! Use `dtype` instead!\n",
            "[INFO|modeling_utils.py:1280] 2025-09-24 20:41:37,379 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/model.safetensors\n",
            "[INFO|modeling_utils.py:2466] 2025-09-24 20:41:37,380 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1055] 2025-09-24 20:41:37,382 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:5721] 2025-09-24 20:41:40,469 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:5729] 2025-09-24 20:41:40,469 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:1010] 2025-09-24 20:41:40,572 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/generation_config.json\n",
            "[INFO|configuration_utils.py:1055] 2025-09-24 20:41:40,572 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"temperature\": 0.7,\n",
            "  \"top_k\": 20,\n",
            "  \"top_p\": 0.8\n",
            "}\n",
            "\n",
            "[INFO|2025-09-24 20:41:40] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
            "[INFO|2025-09-24 20:41:40] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-09-24 20:41:40] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
            "[INFO|2025-09-24 20:41:40] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
            "[INFO|2025-09-24 20:41:40] llamafactory.model.model_utils.misc:143 >> Found linear modules: q_proj,o_proj,v_proj,down_proj,gate_proj,k_proj,up_proj\n",
            "[INFO|2025-09-24 20:41:41] llamafactory.model.loader:143 >> trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n",
            "[INFO|trainer.py:757] 2025-09-24 20:41:41,200 >> Using auto half precision backend\n",
            "[WARNING|trainer.py:985] 2025-09-24 20:41:41,202 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "[INFO|trainer.py:2523] 2025-09-24 20:41:41,866 >> ***** Running training *****\n",
            "[INFO|trainer.py:2524] 2025-09-24 20:41:41,866 >>   Num examples = 2,666\n",
            "[INFO|trainer.py:2525] 2025-09-24 20:41:41,866 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2526] 2025-09-24 20:41:41,866 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:2529] 2025-09-24 20:41:41,866 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:2530] 2025-09-24 20:41:41,866 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2531] 2025-09-24 20:41:41,866 >>   Total optimization steps = 2,001\n",
            "[INFO|trainer.py:2532] 2025-09-24 20:41:41,870 >>   Number of trainable parameters = 18,464,768\n",
            "[INFO|integration_utils.py:869] 2025-09-24 20:41:41,873 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoussefsalah1357\u001b[0m (\u001b[33myoussefsalah1357-new\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m creating run (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/LLaMA-Factory/wandb/run-20250924_204142-rho8eoeq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinetune-llamafactory\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/youssefsalah1357-new/llamafactory\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/youssefsalah1357-new/llamafactory/runs/rho8eoeq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, mcp, openai] in use.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n",
            "{'loss': 0.7762, 'grad_norm': 0.6546964645385742, 'learning_rate': 4.477611940298508e-06, 'epoch': 0.02}\n",
            "{'loss': 0.7204, 'grad_norm': 0.7595220804214478, 'learning_rate': 9.45273631840796e-06, 'epoch': 0.03}\n",
            "{'loss': 0.7476, 'grad_norm': 0.7833483219146729, 'learning_rate': 1.4427860696517415e-05, 'epoch': 0.05}\n",
            "{'loss': 0.7003, 'grad_norm': 0.6480264663696289, 'learning_rate': 1.9402985074626868e-05, 'epoch': 0.06}\n",
            "{'loss': 0.6768, 'grad_norm': 0.6330780982971191, 'learning_rate': 2.437810945273632e-05, 'epoch': 0.08}\n",
            "{'loss': 0.6239, 'grad_norm': 0.5976622104644775, 'learning_rate': 2.935323383084577e-05, 'epoch': 0.09}\n",
            "{'loss': 0.6205, 'grad_norm': 0.6591970324516296, 'learning_rate': 3.432835820895522e-05, 'epoch': 0.11}\n",
            "{'loss': 0.487, 'grad_norm': 0.6143773198127747, 'learning_rate': 3.9303482587064676e-05, 'epoch': 0.12}\n",
            "{'loss': 0.5109, 'grad_norm': 0.617737352848053, 'learning_rate': 4.427860696517413e-05, 'epoch': 0.14}\n",
            "{'loss': 0.471, 'grad_norm': 0.8865456581115723, 'learning_rate': 4.9253731343283586e-05, 'epoch': 0.15}\n",
            "  5% 100/2001 [58:47<19:02:21, 36.06s/it][INFO|trainer.py:4623] 2025-09-24 21:40:31,952 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4625] 2025-09-24 21:40:31,953 >>   Num examples = 100\n",
            "[INFO|trainer.py:4628] 2025-09-24 21:40:31,953 >>   Batch size = 1\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/100 [00:03<02:27,  1.50s/it]\u001b[A\n",
            "  3% 3/100 [00:06<03:41,  2.28s/it]\u001b[A\n",
            "  4% 4/100 [00:09<04:18,  2.69s/it]\u001b[A\n",
            "  5% 5/100 [00:12<04:18,  2.72s/it]\u001b[A\n",
            "  6% 6/100 [00:14<04:04,  2.60s/it]\u001b[A\n",
            "  7% 7/100 [00:18<04:24,  2.85s/it]\u001b[A\n",
            "  8% 8/100 [00:21<04:37,  3.01s/it]\u001b[A\n",
            "  9% 9/100 [00:25<04:44,  3.13s/it]\u001b[A\n",
            " 10% 10/100 [00:28<04:48,  3.20s/it]\u001b[A\n",
            " 11% 11/100 [00:31<04:49,  3.26s/it]\u001b[A\n",
            " 12% 12/100 [00:33<04:01,  2.75s/it]\u001b[A\n",
            " 13% 13/100 [00:36<04:02,  2.79s/it]\u001b[A\n",
            " 14% 14/100 [00:39<04:02,  2.82s/it]\u001b[A\n",
            " 15% 15/100 [00:42<04:01,  2.84s/it]\u001b[A\n",
            " 16% 16/100 [00:44<03:53,  2.78s/it]\u001b[A\n",
            " 17% 17/100 [00:46<03:39,  2.65s/it]\u001b[A\n",
            " 18% 18/100 [00:50<03:54,  2.86s/it]\u001b[A\n",
            " 19% 19/100 [00:53<04:03,  3.01s/it]\u001b[A\n",
            " 20% 20/100 [00:57<04:09,  3.11s/it]\u001b[A\n",
            " 21% 21/100 [01:00<04:11,  3.19s/it]\u001b[A\n",
            " 22% 22/100 [01:02<03:38,  2.80s/it]\u001b[A\n",
            " 23% 23/100 [01:05<03:48,  2.96s/it]\u001b[A\n",
            " 24% 24/100 [01:08<03:43,  2.94s/it]\u001b[A\n",
            " 25% 25/100 [01:11<03:50,  3.07s/it]\u001b[A\n",
            " 26% 26/100 [01:14<03:25,  2.78s/it]\u001b[A\n",
            " 27% 27/100 [01:15<03:01,  2.48s/it]\u001b[A\n",
            " 28% 28/100 [01:19<03:17,  2.75s/it]\u001b[A\n",
            " 29% 29/100 [01:22<03:28,  2.93s/it]\u001b[A\n",
            " 30% 30/100 [01:25<03:34,  3.06s/it]\u001b[A\n",
            " 31% 31/100 [01:29<03:37,  3.16s/it]\u001b[A\n",
            " 32% 32/100 [01:32<03:39,  3.22s/it]\u001b[A\n",
            " 33% 33/100 [01:36<03:39,  3.27s/it]\u001b[A\n",
            " 34% 34/100 [01:38<03:22,  3.06s/it]\u001b[A\n",
            " 35% 35/100 [01:42<03:25,  3.16s/it]\u001b[A\n",
            " 36% 36/100 [01:45<03:26,  3.23s/it]\u001b[A\n",
            " 37% 37/100 [01:48<03:17,  3.14s/it]\u001b[A\n",
            " 38% 38/100 [01:50<02:57,  2.87s/it]\u001b[A\n",
            " 39% 39/100 [01:53<03:04,  3.02s/it]\u001b[A\n",
            " 40% 40/100 [01:57<03:07,  3.13s/it]\u001b[A\n",
            " 41% 41/100 [01:59<02:56,  2.98s/it]\u001b[A\n",
            " 42% 42/100 [02:03<02:59,  3.10s/it]\u001b[A\n",
            " 43% 43/100 [02:06<03:01,  3.18s/it]\u001b[A\n",
            " 44% 44/100 [02:10<03:00,  3.23s/it]\u001b[A\n",
            " 45% 45/100 [02:11<02:27,  2.68s/it]\u001b[A\n",
            " 46% 46/100 [02:14<02:35,  2.88s/it]\u001b[A\n",
            " 47% 47/100 [02:16<02:17,  2.60s/it]\u001b[A\n",
            " 48% 48/100 [02:19<02:15,  2.61s/it]\u001b[A\n",
            " 49% 49/100 [02:22<02:22,  2.79s/it]\u001b[A\n",
            " 50% 50/100 [02:24<02:07,  2.56s/it]\u001b[A\n",
            " 51% 51/100 [02:27<02:11,  2.69s/it]\u001b[A\n",
            " 52% 52/100 [02:30<02:13,  2.79s/it]\u001b[A\n",
            " 53% 53/100 [02:33<02:06,  2.68s/it]\u001b[A\n",
            " 54% 54/100 [02:35<02:01,  2.64s/it]\u001b[A\n",
            " 55% 55/100 [02:38<02:01,  2.71s/it]\u001b[A\n",
            " 56% 56/100 [02:41<02:07,  2.90s/it]\u001b[A\n",
            " 57% 57/100 [02:44<01:58,  2.77s/it]\u001b[A\n",
            " 58% 58/100 [02:46<01:52,  2.67s/it]\u001b[A\n",
            " 59% 59/100 [02:49<01:45,  2.57s/it]\u001b[A\n",
            " 60% 60/100 [02:51<01:40,  2.50s/it]\u001b[A\n",
            " 61% 61/100 [02:53<01:34,  2.42s/it]\u001b[A\n",
            " 62% 62/100 [02:57<01:42,  2.71s/it]\u001b[A\n",
            " 63% 63/100 [03:00<01:47,  2.91s/it]\u001b[A\n",
            " 64% 64/100 [03:01<01:27,  2.42s/it]\u001b[A\n",
            " 65% 65/100 [03:04<01:31,  2.62s/it]\u001b[A\n",
            " 66% 66/100 [03:06<01:20,  2.38s/it]\u001b[A\n",
            " 67% 67/100 [03:09<01:28,  2.67s/it]\u001b[A\n",
            " 68% 68/100 [03:12<01:21,  2.54s/it]\u001b[A\n",
            " 69% 69/100 [03:15<01:26,  2.79s/it]\u001b[A\n",
            " 70% 70/100 [03:18<01:26,  2.88s/it]\u001b[A\n",
            " 71% 71/100 [03:22<01:27,  3.03s/it]\u001b[A\n",
            " 72% 72/100 [03:25<01:27,  3.14s/it]\u001b[A\n",
            " 73% 73/100 [03:28<01:26,  3.21s/it]\u001b[A\n",
            " 74% 74/100 [03:31<01:15,  2.92s/it]\u001b[A\n",
            " 75% 75/100 [03:33<01:12,  2.88s/it]\u001b[A\n",
            " 76% 76/100 [03:36<01:05,  2.72s/it]\u001b[A\n",
            " 77% 77/100 [03:39<01:07,  2.92s/it]\u001b[A\n",
            " 78% 78/100 [03:42<01:06,  3.02s/it]\u001b[A\n",
            " 79% 79/100 [03:45<01:03,  3.05s/it]\u001b[A\n",
            " 80% 80/100 [03:49<01:02,  3.15s/it]\u001b[A\n",
            " 81% 81/100 [03:52<01:01,  3.21s/it]\u001b[A\n",
            " 82% 82/100 [03:54<00:50,  2.82s/it]\u001b[A\n",
            " 83% 83/100 [03:56<00:44,  2.62s/it]\u001b[A\n",
            " 84% 84/100 [03:58<00:37,  2.37s/it]\u001b[A\n",
            " 85% 85/100 [04:01<00:36,  2.43s/it]\u001b[A\n",
            " 86% 86/100 [04:04<00:36,  2.64s/it]\u001b[A\n",
            " 87% 87/100 [04:07<00:37,  2.86s/it]\u001b[A\n",
            " 88% 88/100 [04:10<00:36,  3.01s/it]\u001b[A\n",
            " 89% 89/100 [04:14<00:34,  3.12s/it]\u001b[A\n",
            " 90% 90/100 [04:17<00:31,  3.19s/it]\u001b[A\n",
            " 91% 91/100 [04:21<00:29,  3.25s/it]\u001b[A\n",
            " 92% 92/100 [04:22<00:22,  2.79s/it]\u001b[A\n",
            " 93% 93/100 [04:24<00:18,  2.59s/it]\u001b[A\n",
            " 94% 94/100 [04:27<00:15,  2.52s/it]\u001b[A\n",
            " 95% 95/100 [04:29<00:12,  2.53s/it]\u001b[A\n",
            " 96% 96/100 [04:33<00:11,  2.79s/it]\u001b[A\n",
            " 97% 97/100 [04:36<00:08,  2.86s/it]\u001b[A\n",
            " 98% 98/100 [04:38<00:05,  2.80s/it]\u001b[A\n",
            " 99% 99/100 [04:41<00:02,  2.90s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.4835050702095032, 'eval_runtime': 288.7794, 'eval_samples_per_second': 0.346, 'eval_steps_per_second': 0.346, 'epoch': 0.15}\n",
            "  5% 100/2001 [1:03:36<19:02:21, 36.06s/it]\n",
            "100% 100/100 [04:45<00:00,  3.04s/it]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:4289] 2025-09-24 21:45:20,752 >> Saving model checkpoint to /gdrive/MyDrive/llm-finetuning/new-models/checkpoint-100\n",
            "[INFO|configuration_utils.py:765] 2025-09-24 21:45:21,035 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-09-24 21:45:21,037 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.56.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2394] 2025-09-24 21:45:21,364 >> chat template saved in /gdrive/MyDrive/llm-finetuning/new-models/checkpoint-100/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2563] 2025-09-24 21:45:21,387 >> tokenizer config file saved in /gdrive/MyDrive/llm-finetuning/new-models/checkpoint-100/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2572] 2025-09-24 21:45:21,407 >> Special tokens file saved in /gdrive/MyDrive/llm-finetuning/new-models/checkpoint-100/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2394] 2025-09-24 21:45:22,978 >> chat template saved in /gdrive/MyDrive/llm-finetuning/new-models/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2563] 2025-09-24 21:45:22,984 >> tokenizer config file saved in /gdrive/MyDrive/llm-finetuning/new-models/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2572] 2025-09-24 21:45:22,990 >> Special tokens file saved in /gdrive/MyDrive/llm-finetuning/new-models/special_tokens_map.json\n",
            "{'loss': 0.5021, 'grad_norm': 0.7441906929016113, 'learning_rate': 5.422885572139303e-05, 'epoch': 0.17}\n",
            "{'loss': 0.4799, 'grad_norm': 0.855854868888855, 'learning_rate': 5.920398009950249e-05, 'epoch': 0.18}\n",
            "{'loss': 0.4799, 'grad_norm': 0.8232018351554871, 'learning_rate': 6.417910447761194e-05, 'epoch': 0.2}\n",
            "{'loss': 0.4889, 'grad_norm': 0.9511232972145081, 'learning_rate': 6.91542288557214e-05, 'epoch': 0.21}\n",
            "{'loss': 0.4701, 'grad_norm': 0.7316831350326538, 'learning_rate': 7.412935323383084e-05, 'epoch': 0.23}\n",
            "{'loss': 0.4599, 'grad_norm': 0.7331669926643372, 'learning_rate': 7.910447761194029e-05, 'epoch': 0.24}\n",
            "  8% 160/2001 [1:38:41<19:17:10, 37.71s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Finetuned Model Evaluation"
      ],
      "metadata": {
        "id": "GeKBEof7Xa6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype = torch_dtype\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
      ],
      "metadata": {
        "id": "WXG625DZXcrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model_id = \"/gdrive/MyDrive/youtube-resources/llm-finetuning/models\"\n",
        "model.load_adapter(finetuned_model_id)"
      ],
      "metadata": {
        "id": "dXzybVp2X048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "7bb0d6fe-f709-4f22-c282-8f4ebd14e12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HFValidationError",
          "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/gdrive/MyDrive/youtube-resources/llm-finetuning/models'. Use `repo_type` argument if needed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/gdrive/MyDrive/youtube-resources/llm-finetuning/models'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3837274195.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinetuned_model_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/gdrive/MyDrive/youtube-resources/llm-finetuning/models\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinetuned_model_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/peft.py\u001b[0m in \u001b[0;36mload_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, low_cpu_mem_usage, is_trainable, adapter_kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpeft_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             adapter_config_file = find_adapter_config_file(\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mpeft_model_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/peft_utils.py\u001b[0m in \u001b[0;36mfind_adapter_config_file\u001b[0;34m(model_id, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, _commit_hash)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0madapter_cached_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mADAPTER_CONFIG_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         adapter_cached_filename = cached_file(\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mADAPTER_CONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \"\"\"\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# Now we try to recover if we can find all files correctly in the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         resolved_files = [\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[0m\n\u001b[1;32m    142\u001b[0m ):\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# We try to see if we have a cached version (not up to date):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     resolved_file = try_to_load_from_cache(\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         ):\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"token\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;34mf\" '{repo_id}'. Use `repo_type` argument if needed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/gdrive/MyDrive/youtube-resources/llm-finetuning/models'. Use `repo_type` argument if needed."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_resp(messages):\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        model_inputs.input_ids,\n",
        "        max_new_tokens=1024,\n",
        "        do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        "    )\n",
        "\n",
        "    generated_ids = [\n",
        "        output_ids[len(input_ids):]\n",
        "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    return response\n",
        "\n",
        "response = generate_resp(translation_messages)"
      ],
      "metadata": {
        "id": "M45kdkH-XXmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_json(response)"
      ],
      "metadata": {
        "id": "9IghFtP0XtvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tip for Qwen2.5\n",
        "\n",
        "Qwen2.5 oftenly produce chinese characters with some responses. To skip this, use the next class to generate responses.\n",
        "\n",
        "Source:\n",
        "`https://jupyter267.medium.com/how-to-eliminate-the-chance-of-generating-chinese-in-qwen-2-5-2cf919bb0fdc`\n",
        "\n"
      ],
      "metadata": {
        "id": "R4gFkGQA4_BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator:\n",
        "    def __init__(self, model, tokenizer):\n",
        "\n",
        "        self.model, self.tokenizer = model, tokenizer\n",
        "        self.mask = None\n",
        "\n",
        "    def generate(self, messages:list, max_new_tokens: int=2000, temperature:float=0.1):\n",
        "\n",
        "        def logits_processor(token_ids, logits):\n",
        "          # logits_processor default recieve the logits which is the score matrix of each time-step\n",
        "          \"\"\"\n",
        "              A processor to ban Chinese character\n",
        "          \"\"\"\n",
        "          if self.mask is None:\n",
        "              # as we don't know where the Chinses tokens locate at which index\n",
        "              # in the vocabulary but we know how it looks like and the range of it\n",
        "\n",
        "              # decode all the tokens in the vocabulary in order\n",
        "              token_ids = torch.arange(logits.size(-1))\n",
        "              decoded_tokens = self.tokenizer.batch_decode(token_ids.unsqueeze(1), skip_special_tokens=True)\n",
        "\n",
        "              # create a mask tensor to exclude positions of Chinese characters.\n",
        "              # since this process uses a for loop and is time-consuming,\n",
        "              # the result will be stored as a property for later use to ensure it only runs once.\n",
        "              self.mask = torch.tensor([\n",
        "                  # loop through each token in the vocabulary and compare it to Chinese characters.\n",
        "                  any(0x4E00 <= ord(c) <= 0x9FFF or 0x3400 <= ord(c) <= 0x4DBF or 0xF900 <= ord(c) <= 0xFAFF for c in\n",
        "                      token)\n",
        "                  for token in decoded_tokens\n",
        "              ])\n",
        "\n",
        "          # mask the score by - inf\n",
        "          logits[:, self.mask] = -float(\"inf\")\n",
        "          return logits\n",
        "\n",
        "        # this step transforms the messages into a string,\n",
        "        # adding special tokens e.g separate tokens between system content user queries\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True,\n",
        "        )\n",
        "\n",
        "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        generated_ids = self.model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            # add the logits_processor here\n",
        "            logits_processor=[logits_processor]\n",
        "        )\n",
        "        generated_ids = [\n",
        "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        return response"
      ],
      "metadata": {
        "id": "7LtXq5y95CA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define an object\n",
        "llm = Generator(model, tokenizer)\n",
        "\n",
        "# generate a response without chinese characters\n",
        "response = llm.generate(details_extraction_messages)\n",
        "print( parse_json(response) )\n",
        "\n",
        "response = llm.generate(translation_messages)\n",
        "print( parse_json(response) )"
      ],
      "metadata": {
        "id": "nsA7F8wD5XVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost Estimation"
      ],
      "metadata": {
        "id": "oC9_nqQaZKWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "start_time = datetime.now()\n",
        "fake = Faker('ar')\n",
        "\n",
        "input_tokens = 0\n",
        "output_tokens = 0\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "    prompt = fake.text(max_nb_chars=random.randint(150, 200))\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = generate_resp(messages)\n",
        "\n",
        "    input_tokens += len(tokenizer.apply_chat_template(messages))\n",
        "    output_tokens += len(tokenizer.encode(response))\n",
        "\n",
        "total_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(f\"Total Time: {total_time} seconds\")\n",
        "print(f\"Input Tokens: {input_tokens}\")\n",
        "print(f\"Output Tokens: {output_tokens}\")\n",
        "print(f\"Total Tokens: {input_tokens + output_tokens}\")"
      ],
      "metadata": {
        "id": "FK_FWdKeZMnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total Time: 387.838115 seconds\n",
        "# Input Tokens: 2446\n",
        "# Output Tokens: 7375\n",
        "# Total Tokens: 9821"
      ],
      "metadata": {
        "id": "l5qgKwWWakuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9821  / 388"
      ],
      "metadata": {
        "id": "QQRCACPaZwOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## vLLM"
      ],
      "metadata": {
        "id": "GOC2oP97bkOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "adapter_model_id = \"/gdrive/MyDrive/youtube-resources/llm-finetuning/models\"\n",
        "\n",
        "\n",
        "!nohup vllm serve \"{base_model_id}\" --dtype=half --gpu-memory-utilization 0.8 --max_lora_rank 64 --enable-lora --lora-modules news-lora=\"{adapter_model_id}\" &\n"
      ],
      "metadata": {
        "id": "Zr72ssnKbrwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 30 nohup.out"
      ],
      "metadata": {
        "id": "pHMHHfA9dLta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "TBZ2Du8tdjSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(\n",
        "    translation_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")"
      ],
      "metadata": {
        "id": "n6Gor_fVdW-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vllm_model_id = \"news-lora\"\n",
        "\n",
        "llm_response = requests.post(\"http://localhost:8000/v1/completions\", json={\n",
        "    \"model\": vllm_model_id,\n",
        "    \"prompt\": prompt,\n",
        "    \"max_tokens\": 1000,\n",
        "    \"temperature\": 0.3\n",
        "})\n",
        "\n",
        "llm_response.json()"
      ],
      "metadata": {
        "id": "JYPDkJ_Adp7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Testing"
      ],
      "metadata": {
        "id": "a3p1nGLyedA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile locust.py\n",
        "\n",
        "import random\n",
        "import json\n",
        "from locust import HttpUser, task, between, constant\n",
        "from transformers import AutoTokenizer\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker('ar')\n",
        "\n",
        "class CompletionLoadTest(HttpUser):\n",
        "    wait_time = between(1, 3)\n",
        "\n",
        "    @task\n",
        "    def post_completion(self):\n",
        "        model_id = \"news-lora\"\n",
        "        prompt = fake.text(max_nb_chars=random.randint(150, 200))\n",
        "\n",
        "        message = {\n",
        "            \"model\": model_id,\n",
        "            \"prompt\": prompt,\n",
        "            \"max_tokens\": 512,\n",
        "            \"temperature\": 0.3\n",
        "        }\n",
        "\n",
        "        llm_response = self.client.post(\"/v1/completions\", json=message)\n",
        "\n",
        "        if llm_response.status_code == 200:\n",
        "            with open(\"./vllm_tokens.txt\", \"a\") as dest:\n",
        "                dest.write(json.dumps({\n",
        "                    \"prompt\": prompt,\n",
        "                    \"response\": llm_response.json()[\"choices\"][0][\"text\"],\n",
        "                }, ensure_ascii=False) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "lOZYakDneeoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!locust --headless -f locust.py --host=http://localhost:8000 -u 20 -r 1 -t \"60s\" --html=locust_results.html"
      ],
      "metadata": {
        "id": "DYPw83hzfeNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vllm_tokens = [\n",
        "    json.loads(line.strip())\n",
        "    for line in open(\"./vllm_tokens.txt\") if line.strip() != \"\"\n",
        "]"
      ],
      "metadata": {
        "id": "oZFSPbufiYbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "\n",
        "total_input_tokens = sum([ len(tokenizer.encode(rec['prompt'])) for rec in vllm_tokens ])\n",
        "total_output_tokens = sum([ len(tokenizer.encode(rec['response'])) for rec in vllm_tokens ])\n",
        "\n",
        "print(f\"Total Input Tokens: {total_input_tokens}\")\n",
        "print(f\"Total Output Tokens: {total_output_tokens}\")"
      ],
      "metadata": {
        "id": "HCwHMzVnigg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "37840 / 60"
      ],
      "metadata": {
        "id": "xOpAbHLSioBz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}